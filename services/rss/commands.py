import logging
import asyncio
import re
import time
from .manager import RSSManager
from pathlib import Path
from urllib.parse import urlparse
from core.config import telegram_config
from telegram import Update, Bot, InputMediaPhoto
from telegram.ext import ContextTypes, CommandHandler, Application
from datetime import datetime

rss_manager = RSSManager()


async def send_update_notification(
    bot: Bot,
    url: str,
    new_entries: list[dict],
    xml_content: str | None,
    target_chat: str = None,
) -> None:
    """
    å‘é€Feedæ›´æ–°é€šçŸ¥ï¼ŒåŒ…æ‹¬æ–°å¢æ¡ç›®åˆ—è¡¨ã€‚
    ä½¿ç”¨æ™ºèƒ½æ¶ˆæ¯å‘é€ï¼š
    - å›¾ç‰‡ä¸ºä¸»æ¨¡å¼ï¼ˆâ‰¥2å¼ å›¾ç‰‡ï¼‰ï¼šåª’ä½“ç»„ + ç®€æ´caption
    - æ–‡å­—ä¸ºä¸»æ¨¡å¼ï¼ˆ<2å¼ å›¾ç‰‡ï¼‰ï¼šå®Œæ•´æ–‡å­—å†…å®¹ + å›¾ç‰‡è¡¥å……
    - æ”¯æŒå‡è¡¡åˆ†æ‰¹ï¼Œæ¯æ‰¹æœ€å¤š10å¼ å›¾ç‰‡ï¼Œåˆ†å¸ƒæ›´å‡åŒ€
    """
    chat_id = target_chat or telegram_config["target_chat"]
    if not chat_id:
        logging.error("æœªé…ç½®å‘é€ç›®æ ‡ï¼Œè¯·æ£€æŸ¥TELEGRAM_TARGET_CHATç¯å¢ƒå˜é‡")
        return

    domain = urlparse(url).netloc

    try:
        # åªå‘é€æ¡ç›®å†…å®¹ï¼Œä¸å‘é€å¼€å§‹å’Œç»“æŸé€šçŸ¥
        if new_entries:
            logging.info(f"å¼€å§‹å‘é€ {len(new_entries)} ä¸ªæ¡ç›® for {domain}")

            for i, entry in enumerate(new_entries, 1):
                try:
                    # å‘é€æ¡ç›®æ¶ˆæ¯ï¼ˆåŒ…å«å›¾ç‰‡ï¼‰
                    await send_entry_with_media(bot, chat_id, entry, i, len(new_entries))
                    logging.info(f"å·²å‘é€æ¡ç›®: {entry.get('title', 'Unknown')}")

                    # æ§åˆ¶å‘é€é€Ÿåº¦ï¼Œé¿å…flood exceed
                    # Telegramé™åˆ¶ï¼šåŒä¸€èŠå¤©æ¯ç§’æœ€å¤š1æ¡æ¶ˆæ¯ï¼Œæ¯åˆ†é’Ÿæœ€å¤š20æ¡æ¶ˆæ¯
                    if i % 10 == 0:  # æ¯10æ¡æ¶ˆæ¯æš‚åœ1åˆ†é’Ÿ
                        logging.info(f"å·²å‘é€10æ¡æ¶ˆæ¯ï¼Œæš‚åœ60ç§’é¿å…flood exceed...")
                        await asyncio.sleep(60)
                    else:
                        # æ¯æ¡æ¶ˆæ¯é—´éš”8ç§’ï¼Œç¡®ä¿ä¸ä¼šè§¦å‘flood control
                        logging.debug(f"ç­‰å¾…8ç§’åå‘é€ä¸‹ä¸€æ¡ç›®...")
                        await asyncio.sleep(8)

                except Exception as e:
                    logging.error(f"å‘é€æ¡ç›®å¤±è´¥: {entry.get('title', 'Unknown')}, é”™è¯¯: {str(e)}")
                    # å‡ºé”™åä¹Ÿè¦ç­‰å¾…ï¼Œé¿å…è¿ç»­é”™è¯¯
                    await asyncio.sleep(5)
                    continue

            logging.info(f"å·²å‘é€ {len(new_entries)} ä¸ªæ¡ç›® for {domain}")
        else:
            logging.info(f"{domain} æ— æ–°å¢å†…å®¹ï¼Œè·³è¿‡å‘é€")
    except Exception as e:
        logging.error(f"å‘é€Feedæ›´æ–°æ¶ˆæ¯å¤±è´¥ for {url}: {str(e)}", exc_info=True)


def extract_and_clean_images(content: str) -> list[str]:
    """
    æå–å¹¶æ¸…ç†å›¾ç‰‡URL

    Args:
        content: HTMLå†…å®¹

    Returns:
        list[str]: æ¸…ç†åçš„æœ‰æ•ˆå›¾ç‰‡URLåˆ—è¡¨
    """
    images = []
    if not content:
        return images

    img_pattern = r'<img[^>]+src=["\']([^"\']+)["\'][^>]*>'
    raw_images = re.findall(img_pattern, content, re.IGNORECASE)
    logging.info(f"æå–åˆ° {len(raw_images)} å¼ åŸå§‹å›¾ç‰‡")

    # æ¸…ç†å’ŒéªŒè¯å›¾ç‰‡URL
    for img_url in raw_images:
        # æ¸…ç†HTMLå®ä½“ç¼–ç 
        clean_url = img_url.replace('&amp;', '&').replace('&lt;', '<').replace('&gt;', '>')
        clean_url = clean_url.replace('&quot;', '"').strip()

        # è¿‡æ»¤æ‰æ˜æ˜¾çš„å°å›¾æ ‡å’Œè£…é¥°å›¾ç‰‡
        if any(keyword in clean_url.lower() for keyword in ['icon', 'logo', 'avatar', 'emoji', 'button']):
            logging.debug(f"è¿‡æ»¤è£…é¥°å›¾ç‰‡: {clean_url}")
            continue

        # éªŒè¯URLæ ¼å¼
        if clean_url.startswith(('http://', 'https://')):
            images.append(clean_url)
            logging.debug(f"æ·»åŠ æœ‰æ•ˆå›¾ç‰‡: {clean_url}")
        else:
            logging.warning(f"è·³è¿‡æ— æ•ˆå›¾ç‰‡URL: {clean_url}")

    logging.info(f"æ¸…ç†åæœ‰æ•ˆå›¾ç‰‡æ•°é‡: {len(images)}")

    # è®°å½•å‰å‡ å¼ å›¾ç‰‡URLç”¨äºè°ƒè¯•
    for i, img_url in enumerate(images[:3], 1):
        logging.info(f"å›¾ç‰‡{i}: {img_url}")

    return images


async def send_image_groups_with_caption(
    bot: Bot,
    chat_id: str,
    title: str,
    author: str,
    images: list[str]
) -> None:
    """
    å‘é€å›¾ç‰‡ç»„ï¼Œç»Ÿä¸€ä½¿ç”¨ç®€æ´captionæ ¼å¼ï¼š#ä½œè€… + title + æ‰¹æ¬¡ä¿¡æ¯
    é€‚ç”¨äºæ‰€æœ‰å›¾ç‰‡å‘é€åœºæ™¯ï¼ˆå›¾ç‰‡ä¸ºä¸»æ¨¡å¼å’Œæ–‡å­—ä¸ºä¸»æ¨¡å¼ï¼‰
    """
    if not images:
        logging.warning("send_image_groups_with_caption: æ²¡æœ‰å›¾ç‰‡å¯å‘é€")
        return

    logging.info(f"å¼€å§‹å‘é€å›¾ç‰‡ç»„: æ ‡é¢˜='{title}', ä½œè€…='{author}', å›¾ç‰‡æ•°é‡={len(images)}")

    # æˆªæ–­æ ‡é¢˜ï¼ˆTelegram captioné™åˆ¶1024å­—ç¬¦ï¼‰
    max_title_length = 100
    original_title = title
    if len(title) > max_title_length:
        title = title[:max_title_length] + "..."
        logging.info(f"æ ‡é¢˜è¿‡é•¿å·²æˆªæ–­: '{original_title}' -> '{title}'")

    # è®¡ç®—å‡è¡¡çš„åˆ†æ‰¹æ–¹æ¡ˆ
    batch_sizes = calculate_balanced_batches(len(images), max_per_batch=10)
    total_batches = len(batch_sizes)

    logging.info(f"å°†å‘é€ {total_batches} ä¸ªåª’ä½“ç»„ï¼Œåˆ†æ‰¹æ–¹æ¡ˆ: {batch_sizes}")

    # æŒ‰ç…§åˆ†æ‰¹æ–¹æ¡ˆå‘é€å›¾ç‰‡
    image_index = 0
    for batch_num, batch_size in enumerate(batch_sizes, 1):
        # è·å–å½“å‰æ‰¹æ¬¡çš„å›¾ç‰‡
        batch_images = images[image_index:image_index + batch_size]
        image_index += batch_size

        logging.info(f"å‡†å¤‡å‘é€ç¬¬ {batch_num}/{total_batches} æ‰¹ï¼ŒåŒ…å« {batch_size} å¼ å›¾ç‰‡")

        # æ„å»ºç®€æ´çš„captionæ ¼å¼ï¼š#ä½œè€… + title + æ‰¹æ¬¡ä¿¡æ¯
        caption_parts = []

        # æ·»åŠ ä½œè€…ï¼ˆå¦‚æœæœ‰ï¼‰
        if author:
            caption_parts.append(f"#{author}")
            logging.debug(f"æ·»åŠ ä½œè€…æ ‡ç­¾: #{author}")

        # æ·»åŠ æ ‡é¢˜
        caption_parts.append(title)

        # åªåœ¨å¤šæ‰¹æ¬¡æ—¶æ˜¾ç¤ºæ‰¹æ¬¡ä¿¡æ¯
        if total_batches > 1:
            batch_info = f"ğŸ“Š {batch_num}/{total_batches}"
            caption_parts.append(batch_info)
            logging.debug(f"æ·»åŠ æ‰¹æ¬¡ä¿¡æ¯: {batch_info}")

        caption = " ".join(caption_parts)
        logging.info(f"ç¬¬ {batch_num} æ‰¹caption: {caption}")

        # æ„å»ºåª’ä½“ç»„
        media_list = []

        # æ¯ä¸ªæ‰¹æ¬¡çš„ç¬¬ä¸€å¼ å›¾ç‰‡åŒ…å«caption
        for j, img_url in enumerate(batch_images):
            if j == 0:  # æ¯æ‰¹çš„ç¬¬ä¸€å¼ å›¾ç‰‡åŒ…å«caption
                media_list.append(InputMediaPhoto(media=img_url, caption=caption))
                logging.debug(f"ç¬¬ {batch_num} æ‰¹ç¬¬1å¼ å›¾ç‰‡(å¸¦caption): {img_url}")
            else:
                media_list.append(InputMediaPhoto(media=img_url))
                logging.debug(f"ç¬¬ {batch_num} æ‰¹ç¬¬{j+1}å¼ å›¾ç‰‡: {img_url}")

        try:
            # å‘é€åª’ä½“ç»„
            await bot.send_media_group(chat_id=chat_id, media=media_list)
            logging.info(f"âœ… æˆåŠŸå‘é€ç¬¬ {batch_num}/{total_batches} æ‰¹åª’ä½“ç»„ ({batch_size}å¼ å›¾ç‰‡)")
        except Exception as e:
            logging.error(f"âŒ å‘é€ç¬¬ {batch_num} æ‰¹åª’ä½“ç»„å¤±è´¥: {str(e)}")

            # å¦‚æœæ˜¯å›¾ç‰‡æ— æ³•è®¿é—®çš„é”™è¯¯ï¼Œè®°å½•è¯¦ç»†ä¿¡æ¯
            if "webpage_media_empty" in str(e):
                logging.error(f"å›¾ç‰‡æ— æ³•è®¿é—®é”™è¯¯ï¼Œæ‰¹æ¬¡ {batch_num} çš„å›¾ç‰‡URL:")
                for j, img_url in enumerate(batch_images):
                    logging.error(f"  å›¾ç‰‡{j+1}: {img_url}")
                # ç»§ç»­å¤„ç†ä¸‹ä¸€æ‰¹ï¼Œä¸ä¸­æ–­æ•´ä¸ªæµç¨‹
                continue

            # å¦‚æœæ˜¯flood controlï¼Œç­‰å¾…åé‡è¯•
            elif "Flood control exceeded" in str(e):
                logging.info(f"é‡åˆ°flood controlï¼Œç­‰å¾…40ç§’åé‡è¯•ç¬¬ {batch_num} æ‰¹...")
                await asyncio.sleep(40)
                try:
                    await bot.send_media_group(chat_id=chat_id, media=media_list)
                    logging.info(f"âœ… é‡è¯•æˆåŠŸå‘é€ç¬¬ {batch_num} æ‰¹åª’ä½“ç»„")
                except Exception as retry_error:
                    logging.error(f"âŒ é‡è¯•å‘é€ç¬¬ {batch_num} æ‰¹ä¹Ÿå¤±è´¥: {str(retry_error)}")
                    # ç»§ç»­å¤„ç†ä¸‹ä¸€æ‰¹ï¼Œä¸ä¸­æ–­æ•´ä¸ªæµç¨‹
                    continue
            else:
                # ç»§ç»­å¤„ç†ä¸‹ä¸€æ‰¹ï¼Œä¸ä¸­æ–­æ•´ä¸ªæµç¨‹
                continue

        # æ¯æ‰¹ä¹‹é—´å¢åŠ å»¶è¿Ÿï¼Œé¿å…flood control
        if batch_num < total_batches:
            logging.debug(f"ç­‰å¾…5ç§’åå‘é€ä¸‹ä¸€æ‰¹...")
            await asyncio.sleep(5)

    logging.info(f"âœ… å›¾ç‰‡ç»„å‘é€å®Œæˆ: å…± {total_batches} æ‰¹ï¼Œ{len(images)} å¼ å›¾ç‰‡")


def extract_entry_info(entry_data, is_feedparser_entry=True):
    """
    ç»Ÿä¸€çš„æ¡ç›®ä¿¡æ¯æå–å‡½æ•°

    Args:
        entry_data: æ¡ç›®æ•°æ®ï¼ˆå¯ä»¥æ˜¯feedparserçš„entryå¯¹è±¡æˆ–å­—å…¸ï¼‰
        is_feedparser_entry: æ˜¯å¦ä¸ºfeedparserè§£æçš„entryå¯¹è±¡

    Returns:
        dict: æ ‡å‡†åŒ–çš„æ¡ç›®ä¿¡æ¯
    """
    try:
        if is_feedparser_entry:
            # feedparserè§£æçš„entryå¯¹è±¡
            entry_info = {
                'title': entry_data.get('title', 'æ— æ ‡é¢˜').strip(),
                'link': entry_data.get('link', '').strip(),
                'summary': entry_data.get('summary', '').strip(),
                'description': entry_data.get('description', '').strip(),
                'author': entry_data.get('author', '').strip(),
                'id': entry_data.get('id', '').strip(),
                'published': '',
                'content': ''
            }

            # è·å–å‘å¸ƒæ—¶é—´
            if hasattr(entry_data, 'published_parsed') and entry_data.published_parsed:
                try:
                    pub_time = datetime.fromtimestamp(time.mktime(entry_data.published_parsed))
                    entry_info['published'] = pub_time.strftime("%Y-%m-%d %H:%M")
                except:
                    pass
            elif entry_data.get('published'):
                entry_info['published'] = entry_data.get('published', '')[:16]

        else:
            # æ‰‹åŠ¨è§£æçš„å­—å…¸ï¼ˆå¦‚showå‘½ä»¤ï¼‰
            entry_info = {
                'title': entry_data.get('title', 'æ— æ ‡é¢˜').strip(),
                'link': entry_data.get('link', '').strip(),
                'summary': entry_data.get('summary', '').strip(),
                'description': entry_data.get('description', '').strip(),
                'author': entry_data.get('author', '').strip(),
                'id': entry_data.get('id', '').strip(),
                'published': entry_data.get('published', '').strip(),
                'content': ''
            }

        # é€‰æ‹©æè¿°å†…å®¹ï¼ˆä¼˜å…ˆä½¿ç”¨descriptionï¼Œå…¶æ¬¡summaryï¼‰
        entry_info['content'] = entry_info['description'] if entry_info['description'] else entry_info['summary']

        logging.debug(f"æå–æ¡ç›®ä¿¡æ¯å®Œæˆ: {entry_info['title']}")
        return entry_info

    except Exception as e:
        logging.error(f"æå–æ¡ç›®ä¿¡æ¯å¤±è´¥: {str(e)}")
        return {
            'title': 'æ— æ ‡é¢˜',
            'link': '',
            'summary': '',
            'description': '',
            'author': '',
            'id': '',
            'published': '',
            'content': ''
        }


async def send_entry_unified(
    bot: Bot,
    chat_id: str,
    entry_info: dict,
    message_type: str = "auto",
    show_analysis: bool = False
) -> None:
    """
    ç»Ÿä¸€çš„æ¡ç›®å‘é€å‡½æ•°ï¼Œæ”¯æŒè‡ªåŠ¨åˆ¤æ–­å’Œå¼ºåˆ¶æ¨¡å¼

    Args:
        bot: Telegram Botå®ä¾‹
        chat_id: ç›®æ ‡èŠå¤©ID
        entry_info: æ ‡å‡†åŒ–çš„æ¡ç›®ä¿¡æ¯å­—å…¸
        message_type: æ¶ˆæ¯ç±»å‹ ("auto", "text", "media")
        show_analysis: æ˜¯å¦æ˜¾ç¤ºåˆ†æä¿¡æ¯ï¼ˆç”¨äºshowå‘½ä»¤ï¼‰
    """
    try:
        title = entry_info['title']
        link = entry_info['link']
        content = entry_info['content']
        published_time = entry_info['published']
        author = entry_info['author']

        logging.info(f"å¼€å§‹å‘é€æ¡ç›®: '{title}'")

        # ä½¿ç”¨å…¬å…±å‡½æ•°æå–å›¾ç‰‡
        images = extract_and_clean_images(content)

        # æ ¹æ®message_typeå‚æ•°å†³å®šæ¶ˆæ¯æ¨¡å¼
        if message_type == "auto":
            # è‡ªåŠ¨åˆ¤æ–­æ¨¡å¼
            is_image_focused = len(images) >= 2
            mode = "å›¾ç‰‡ä¸ºä¸»" if is_image_focused else "æ–‡å­—ä¸ºä¸»"
            mode_reason = f"è‡ªåŠ¨åˆ¤æ–­({len(images)}å¼ å›¾ç‰‡)"
        elif message_type == "text":
            # å¼ºåˆ¶æ–‡å­—ä¸ºä¸»æ¨¡å¼
            is_image_focused = False
            mode = "æ–‡å­—ä¸ºä¸»"
            mode_reason = "å¼ºåˆ¶æŒ‡å®š"
        elif message_type == "media":
            # å¼ºåˆ¶å›¾ç‰‡ä¸ºä¸»æ¨¡å¼
            is_image_focused = True
            mode = "å›¾ç‰‡ä¸ºä¸»"
            mode_reason = "å¼ºåˆ¶æŒ‡å®š"
        else:
            # é»˜è®¤è‡ªåŠ¨åˆ¤æ–­
            is_image_focused = len(images) >= 2
            mode = "å›¾ç‰‡ä¸ºä¸»" if is_image_focused else "æ–‡å­—ä¸ºä¸»"
            mode_reason = f"é»˜è®¤åˆ¤æ–­({len(images)}å¼ å›¾ç‰‡)"

        logging.info(f"æ¡ç›®æ¨¡å¼åˆ¤æ–­: {len(images)}å¼ å›¾ç‰‡ -> {mode}æ¨¡å¼ ({mode_reason})")

        # å¦‚æœéœ€è¦æ˜¾ç¤ºåˆ†æä¿¡æ¯ï¼ˆshowå‘½ä»¤ä¸“ç”¨ï¼‰
        if show_analysis:
            analysis_message = (
                f"ğŸ”§ SHOWå‘½ä»¤åˆ†æç»“æœï¼š\n"
                f"------------------------------------\n"
                f"ğŸ“° æ ‡é¢˜: {title}\n"
                f"ğŸ‘¤ ä½œè€…: {author or 'æ— '}\n"
                f"ğŸ”— é“¾æ¥: {link[:50]}{'...' if len(link) > 50 else ''}\n"
                f"ğŸ•’ æ—¶é—´: {published_time or 'æ— '}\n"
                f"ğŸ–¼ï¸ å›¾ç‰‡æ•°é‡: {len(images)}\n"
                f"âš™ï¸ æŒ‡å®šç±»å‹: {message_type}\n"
                f"ğŸ“Š å®é™…æ¨¡å¼: {mode} ({mode_reason})\n"
                f"------------------------------------\n"
                f"æ­£åœ¨å‘é€å®é™…æ¶ˆæ¯..."
            )
            # è¿™é‡Œéœ€è¦ä»å¤–éƒ¨ä¼ å…¥updateå¯¹è±¡ï¼Œæš‚æ—¶å…ˆç”¨botå‘é€
            await bot.send_message(chat_id=chat_id, text=analysis_message)

        # æ ¹æ®æ¨¡å¼å‘é€æ¶ˆæ¯
        if is_image_focused:
            # å›¾ç‰‡ä¸ºä¸»æ¨¡å¼ï¼šåªå‘é€å›¾ç‰‡ç»„ï¼ˆå¸¦ç®€æ´captionï¼‰
            if images:
                await send_image_groups_with_caption(bot, chat_id, title, author, images)
            else:
                # å¦‚æœå¼ºåˆ¶æŒ‡å®šmediaæ¨¡å¼ä½†æ²¡æœ‰å›¾ç‰‡ï¼Œå‘é€æç¤º
                if message_type == "media":
                    await bot.send_message(chat_id=chat_id, text="âš ï¸ å¼ºåˆ¶æŒ‡å®šå›¾ç‰‡ä¸ºä¸»æ¨¡å¼ï¼Œä½†æœªæ‰¾åˆ°å›¾ç‰‡å†…å®¹")
        else:
            # æ–‡å­—ä¸ºä¸»æ¨¡å¼ï¼šå…ˆå‘é€æ–‡å­—æ¶ˆæ¯ï¼Œå†å‘é€å›¾ç‰‡ç»„
            await send_text_message(bot, chat_id, title, link, content, published_time)

            # å¦‚æœæœ‰å›¾ç‰‡ï¼Œå‘é€å›¾ç‰‡ç»„ï¼ˆå¸¦ç®€æ´captionï¼‰
            if images:
                await asyncio.sleep(3)  # å»¶è¿Ÿé¿å…flood control
                await send_image_groups_with_caption(bot, chat_id, title, author, images)

        logging.info(f"âœ… æ¡ç›®å‘é€å®Œæˆ: '{title}' ({mode})")

    except Exception as e:
        logging.error(f"âŒ å‘é€æ¡ç›®å¤±è´¥: '{entry_info.get('title', 'Unknown')}', é”™è¯¯: {str(e)}")
        raise


async def send_entry_with_media(
    bot: Bot,
    chat_id: str,
    entry: dict,
    current_index: int,
    total_count: int
) -> None:
    """
    å‘é€å•ä¸ªæ¡ç›®ï¼Œæ™ºèƒ½åˆ¤æ–­å›¾ç‰‡ä¸ºä¸»è¿˜æ˜¯æ–‡å­—ä¸ºä¸»
    ï¼ˆé‡æ„åçš„ç‰ˆæœ¬ï¼Œä½¿ç”¨ç»Ÿä¸€çš„å‘é€å‡½æ•°ï¼‰

    Args:
        bot: Telegram Botå®ä¾‹
        chat_id: ç›®æ ‡èŠå¤©ID
        entry: RSSæ¡ç›®æ•°æ®
        current_index: å½“å‰æ¡ç›®åºå·ï¼ˆä»…ç”¨äºæ—¥å¿—ï¼‰
        total_count: æ€»æ¡ç›®æ•°ï¼ˆä»…ç”¨äºæ—¥å¿—ï¼‰
    """
    try:
        logging.info(f"å¤„ç†æ¡ç›® {current_index}/{total_count}: '{entry.get('title', 'Unknown')}'")

        # ä½¿ç”¨ç»Ÿä¸€çš„æ¡ç›®ä¿¡æ¯æå–å‡½æ•°
        entry_info = extract_entry_info(entry, is_feedparser_entry=True)

        # ä½¿ç”¨ç»Ÿä¸€çš„å‘é€å‡½æ•°
        await send_entry_unified(bot, chat_id, entry_info, message_type="auto", show_analysis=False)

    except Exception as e:
        logging.error(f"âŒ å‘é€æ¡ç›®å¤±è´¥: '{entry.get('title', 'Unknown')}', é”™è¯¯: {str(e)}")
        # ä¸å†ä½¿ç”¨é™çº§æœºåˆ¶ï¼Œé¿å…é‡å¤æ¶ˆæ¯
        raise


def calculate_balanced_batches(total_images: int, max_per_batch: int = 10) -> list[int]:
    """
    è®¡ç®—å‡è¡¡çš„å›¾ç‰‡åˆ†æ‰¹æ–¹æ¡ˆ

    Args:
        total_images: æ€»å›¾ç‰‡æ•°é‡
        max_per_batch: æ¯æ‰¹æœ€å¤§å›¾ç‰‡æ•°é‡

    Returns:
        list[int]: æ¯æ‰¹çš„å›¾ç‰‡æ•°é‡åˆ—è¡¨
    """
    if total_images <= max_per_batch:
        logging.info(f"å›¾ç‰‡æ•°é‡ {total_images} â‰¤ {max_per_batch}ï¼Œä½¿ç”¨å•æ‰¹æ–¹æ¡ˆ: [1æ‰¹{total_images}å¼ ]")
        return [total_images]

    # è®¡ç®—æœ€å°‘éœ€è¦å¤šå°‘æ‰¹
    min_batches = (total_images + max_per_batch - 1) // max_per_batch

    # è®¡ç®—å¹³å‡æ¯æ‰¹çš„æ•°é‡
    avg_per_batch = total_images // min_batches
    remainder = total_images % min_batches

    # æ„å»ºåˆ†æ‰¹æ–¹æ¡ˆ
    batches = []
    for i in range(min_batches):
        # å‰remainderæ‰¹å¤šåˆ†é…1å¼ å›¾ç‰‡
        batch_size = avg_per_batch + (1 if i < remainder else 0)
        batches.append(batch_size)

    # è®¡ç®—æ—§æ–¹æ¡ˆå¯¹æ¯”
    old_batches = [max_per_batch] * (total_images // max_per_batch)
    if total_images % max_per_batch > 0:
        old_batches.append(total_images % max_per_batch)

    old_diff = max(old_batches) - min(old_batches) if len(old_batches) > 1 else 0
    new_diff = max(batches) - min(batches) if len(batches) > 1 else 0

    logging.info(f"æ™ºèƒ½åˆ†æ‰¹ç®—æ³•: {total_images}å¼ å›¾ç‰‡")
    logging.info(f"  æ—§æ–¹æ¡ˆ: {old_batches} (æœ€å¤§å·®å¼‚: {old_diff}å¼ )")
    logging.info(f"  æ–°æ–¹æ¡ˆ: {batches} (æœ€å¤§å·®å¼‚: {new_diff}å¼ )")
    logging.info(f"  ä¼˜åŒ–æ•ˆæœ: å·®å¼‚å‡å°‘ {old_diff - new_diff}å¼ ")

    return batches


async def send_text_message(
    bot: Bot,
    chat_id: str,
    title: str,
    link: str,
    content: str,
    published_time: str
) -> None:
    """
    å‘é€çº¯æ–‡å­—æ¶ˆæ¯
    """
    # æ„å»ºå®Œæ•´çš„æ–‡å­—æ¶ˆæ¯
    text_message = f"ğŸ•’ {published_time}\n" if published_time else ""
    text_message += f"ğŸ“° {title}\n"

    if link:
        text_message += f"ğŸ”— {link}\n"

    if content:
        # ç§»é™¤HTMLæ ‡ç­¾ä½†ä¿ç•™æ–‡æœ¬å†…å®¹
        clean_content = re.sub(r'<[^>]+>', '', content)
        clean_content = clean_content.replace('&nbsp;', ' ').replace('&amp;', '&')
        clean_content = clean_content.replace('&lt;', '<').replace('&gt;', '>')
        clean_content = clean_content.replace('&quot;', '"').strip()

        # é™åˆ¶å†…å®¹é•¿åº¦
        if len(clean_content) > 400:
            clean_content = clean_content[:400] + "..."

        if clean_content:
            text_message += f"\nğŸ“ {clean_content}\n"

    # å‘é€æ–‡å­—æ¶ˆæ¯
    try:
        await bot.send_message(
            chat_id=chat_id,
            text=text_message,
            disable_web_page_preview=False
        )
        logging.info(f"âœ… æˆåŠŸå‘é€æ–‡å­—æ¶ˆæ¯")
    except Exception as e:
        logging.error(f"âŒ å‘é€æ–‡å­—æ¶ˆæ¯å¤±è´¥: {str(e)}")
        if "Flood control exceeded" in str(e):
            logging.info(f"é‡åˆ°flood controlï¼Œç­‰å¾…40ç§’åé‡è¯•...")
            await asyncio.sleep(40)
            try:
                await bot.send_message(
                    chat_id=chat_id,
                    text=text_message,
                    disable_web_page_preview=False
                )
                logging.info(f"âœ… é‡è¯•æˆåŠŸå‘é€æ–‡å­—æ¶ˆæ¯")
            except Exception as retry_error:
                logging.error(f"âŒ é‡è¯•å‘é€æ–‡å­—æ¶ˆæ¯ä¹Ÿå¤±è´¥: {str(retry_error)}")
                raise
        else:
            raise


async def add_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """å¤„ç† /add å‘½ä»¤"""
    user = update.message.from_user
    chat_id = update.message.chat_id
    logging.info(f"æ”¶åˆ°ADDå‘½ä»¤ - ç”¨æˆ·: {user.username}(ID:{user.id}) èŠå¤©ID: {chat_id}")

    if not context.args:
        logging.info("æ˜¾ç¤ºADDå‘½ä»¤å¸®åŠ©ä¿¡æ¯")
        await update.message.reply_text(
            "è¯·æä¾›RSS/Feedçš„URLå’Œç›®æ ‡é¢‘é“ID\n"
            "æ ¼å¼ï¼š/add <RSS_URL> <CHAT_ID>\n\n"
            "ä¾‹å¦‚ï¼š\n"
            "/add https://example.com/feed.xml @my_channel\n"
            "/add https://example.com/feed.xml -1001234567890\n\n"
            "æ”¯æŒæ ‡å‡†çš„RSS 2.0å’ŒAtom 1.0æ ¼å¼\n"
            "æ³¨æ„ï¼šé¦–æ¬¡æ·»åŠ è®¢é˜…æºæ—¶ï¼Œä¼šå±•ç¤ºæ‰€æœ‰ç°æœ‰å†…å®¹"
        )
        return

    if len(context.args) < 2:
        await update.message.reply_text(
            "âŒ å‚æ•°ä¸è¶³\n"
            "è¯·æä¾›RSS URLå’Œç›®æ ‡é¢‘é“ID\n"
            "æ ¼å¼ï¼š/add <RSS_URL> <CHAT_ID>\n\n"
            "ä¾‹å¦‚ï¼š/add https://example.com/feed.xml @my_channel"
        )
        return

    url = context.args[0]
    target_chat_id = context.args[1]

    logging.info(f"æ‰§è¡Œaddå‘½ä»¤ï¼ŒURL: {url}, ç›®æ ‡é¢‘é“: {target_chat_id}")

    # éªŒè¯é¢‘é“IDæ ¼å¼
    if not (target_chat_id.startswith('@') or target_chat_id.startswith('-') or target_chat_id.isdigit()):
        await update.message.reply_text(
            "âŒ æ— æ•ˆçš„é¢‘é“IDæ ¼å¼\n"
            "æ”¯æŒçš„æ ¼å¼ï¼š\n"
            "- @channel_name (é¢‘é“ç”¨æˆ·å)\n"
            "- -1001234567890 (é¢‘é“æ•°å­—ID)\n"
            "- 1234567890 (ç”¨æˆ·æ•°å­—ID)"
        )
        return

    success, error_msg, xml_content, entries = rss_manager.add_feed(url, target_chat_id)

    if success:
        if "é¦–æ¬¡æ·»åŠ " in error_msg:
            await update.message.reply_text(
                f"âœ… æˆåŠŸæ·»åŠ Feedç›‘æ§ï¼š{url}\n"
                f"ğŸ“º ç›®æ ‡é¢‘é“ï¼š{target_chat_id}\n"
                f"ğŸ“‹ è¿™æ˜¯é¦–æ¬¡æ·»åŠ ï¼Œå°†å±•ç¤ºæ‰€æœ‰ç°æœ‰å†…å®¹ï¼ˆå…± {len(entries)} æ¡ï¼‰"
            )
        elif "ä»Šå¤©å·²ç»æ›´æ–°è¿‡æ­¤Feed" in error_msg:
            await update.message.reply_text(f"è¯¥Feedå·²åœ¨ç›‘æ§åˆ—è¡¨ä¸­ï¼Œä»Šå¤©å·²æ›´æ–°è¿‡")
        else:
            await update.message.reply_text(
                f"âœ… æˆåŠŸæ·»åŠ Feedç›‘æ§ï¼š{url}\n"
                f"ğŸ“º ç›®æ ‡é¢‘é“ï¼š{target_chat_id}"
            )

        # å‘é€æ›´æ–°é€šçŸ¥åˆ°æŒ‡å®šé¢‘é“
        await send_update_notification(context.bot, url, entries, xml_content, target_chat_id)
        logging.info(f"å·²å°è¯•å‘é€æ›´æ–°é€šçŸ¥ for {url} to {target_chat_id} after add command")

    else:
        logging.error(f"æ·»åŠ Feedç›‘æ§å¤±è´¥: {url} åŸå› : {error_msg}")
        await update.message.reply_text(
            f"âŒ æ·»åŠ Feedç›‘æ§å¤±è´¥ï¼š{url}\nåŸå› ï¼š{error_msg}"
        )


async def del_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """å¤„ç† /del å‘½ä»¤"""
    user = update.message.from_user
    chat_id = update.message.chat_id
    logging.info(f"æ”¶åˆ°DELå‘½ä»¤ - ç”¨æˆ·: {user.username}(ID:{user.id}) èŠå¤©ID: {chat_id}")

    if not context.args:
        logging.warning("delå‘½ä»¤ç¼ºå°‘URLå‚æ•°")
        await update.message.reply_text(
            "è¯·æä¾›è¦åˆ é™¤çš„RSS/Feedé“¾æ¥\nä¾‹å¦‚ï¼š/del https://example.com/feed.xml"
        )
        return

    url = context.args[0]
    logging.info(f"æ‰§è¡Œdelå‘½ä»¤ï¼ŒURL: {url}")
    success, error_msg = rss_manager.remove_feed(url)
    if success:
        logging.info(f"æˆåŠŸåˆ é™¤RSSè®¢é˜…: {url}")
        await update.message.reply_text(f"æˆåŠŸåˆ é™¤RSSè®¢é˜…ï¼š{url}")
    else:
        logging.error(f"åˆ é™¤RSSè®¢é˜…å¤±è´¥: {url} åŸå› : {error_msg}")
        await update.message.reply_text(
            f"åˆ é™¤RSSè®¢é˜…å¤±è´¥ï¼š{url}\nåŸå› ï¼š{error_msg}"
        )


async def list_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """å¤„ç† /list å‘½ä»¤"""
    user = update.message.from_user
    chat_id = update.message.chat_id
    logging.info(f"æ”¶åˆ°LISTå‘½ä»¤ - ç”¨æˆ·: {user.username}(ID:{user.id}) èŠå¤©ID: {chat_id}")

    feeds = rss_manager.get_feeds()
    if not feeds:
        logging.info("RSSè®¢é˜…åˆ—è¡¨ä¸ºç©º")
        await update.message.reply_text("å½“å‰æ²¡æœ‰RSSè®¢é˜…")
        return

    # æ„å»ºè®¢é˜…åˆ—è¡¨ï¼Œæ˜¾ç¤ºURLå’Œå¯¹åº”çš„é¢‘é“ID
    feed_list = []
    for url, target_chat_id in feeds.items():
        if target_chat_id:
            feed_list.append(f"- {url} â†’ {target_chat_id}")
        else:
            feed_list.append(f"- {url} â†’ (æœªè®¾ç½®é¢‘é“)")

    feed_list_text = "\n".join(feed_list)
    logging.info(f"æ˜¾ç¤ºRSSè®¢é˜…åˆ—è¡¨ï¼Œå…± {len(feeds)} ä¸ª")
    await update.message.reply_text(f"å½“å‰RSSè®¢é˜…åˆ—è¡¨ï¼š\n{feed_list_text}")


def register_commands(application: Application) -> None:
    """æ³¨å†ŒRSSç›¸å…³çš„å‘½ä»¤å¤„ç†å™¨"""
    application.add_handler(CommandHandler("add", add_command))
    application.add_handler(CommandHandler("del", del_command))
    application.add_handler(CommandHandler("list", list_command))
    application.add_handler(CommandHandler("news", news_command))
    application.add_handler(CommandHandler("show", show_command))  # å¼€å‘è€…è°ƒè¯•å‘½ä»¤


async def news_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """å¤„ç† /news å‘½ä»¤ - å¼ºåˆ¶æ£€æŸ¥æ‰€æœ‰è®¢é˜…æºå¹¶å‘é€å·®å¼‚å†…å®¹"""
    user = update.message.from_user
    chat_id = update.message.chat_id
    logging.info(f"æ”¶åˆ°NEWSå‘½ä»¤ - ç”¨æˆ·: {user.username}(ID:{user.id}) èŠå¤©ID: {chat_id}")

    feeds = rss_manager.get_feeds()
    if not feeds:
        await update.message.reply_text("âŒ å½“å‰æ²¡æœ‰ç›‘æ§ä»»ä½•Feedè®¢é˜…æº")
        return

    await update.message.reply_text(
        f"ğŸ”„ å¼€å§‹å¼ºåˆ¶æ£€æŸ¥ {len(feeds)} ä¸ªè®¢é˜…æºçš„æ›´æ–°...\n"
        f"è¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼Œè¯·ç¨å€™ã€‚"
    )

    # ç”¨äºå­˜å‚¨æ‰€æœ‰æ–°å¢çš„æ¡ç›®
    all_new_entries = []
    success_count = 0
    error_count = 0

    for url, target_chat_id in feeds.items():
        try:
            logging.info(f"å¼ºåˆ¶æ£€æŸ¥è®¢é˜…æº: {url} -> é¢‘é“: {target_chat_id}")

            # ä½¿ç”¨download_and_parse_feedæ–¹æ³•è·å–å·®å¼‚å†…å®¹
            success, error_msg, xml_content, new_entries = rss_manager.download_and_parse_feed(url)

            if success:
                success_count += 1
                if new_entries:
                    logging.info(f"è®¢é˜…æº {url} å‘ç° {len(new_entries)} ä¸ªæ–°æ¡ç›®")
                    # å‘é€æ›´æ–°é€šçŸ¥åˆ°ç»‘å®šçš„é¢‘é“
                    await send_update_notification(context.bot, url, new_entries, xml_content, target_chat_id)
                    all_new_entries.extend(new_entries)
                else:
                    logging.info(f"è®¢é˜…æº {url} æ— æ–°å¢å†…å®¹")
            else:
                error_count += 1
                logging.warning(f"è®¢é˜…æº {url} æ£€æŸ¥å¤±è´¥: {error_msg}")

        except Exception as e:
            error_count += 1
            logging.error(f"æ£€æŸ¥è®¢é˜…æºå¤±è´¥: {url}, é”™è¯¯: {str(e)}")

    # å‘é€æ£€æŸ¥ç»“æœæ‘˜è¦
    result_message = (
        f"âœ… å¼ºåˆ¶æ£€æŸ¥å®Œæˆ\n"
        f"ğŸ“Š æˆåŠŸ: {success_count} ä¸ª\n"
        f"âŒ å¤±è´¥: {error_count} ä¸ª\n"
        f"ğŸ“ˆ å‘ç°æ–°å†…å®¹: {len(all_new_entries)} æ¡"
    )

    if all_new_entries:
        result_message += f"\n\nâœ… æ‰€æœ‰å†…å®¹å·²æ¨é€åˆ°å¯¹åº”é¢‘é“"
        await update.message.reply_text(result_message)
    else:
        result_message += f"\n\nğŸ’¡ æ‰€æœ‰è®¢é˜…æºéƒ½æ²¡æœ‰æ–°å¢å†…å®¹"
        await update.message.reply_text(result_message)

    logging.info(f"NEWSå‘½ä»¤æ‰§è¡Œå®Œæˆï¼Œå…±å¤„ç† {len(feeds)} ä¸ªè®¢é˜…æºï¼Œå‘ç° {len(all_new_entries)} æ¡æ–°å†…å®¹")


async def show_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """å¤„ç† /show å‘½ä»¤ - å¼€å‘è€…ä¸“ç”¨ï¼Œç”¨äºæµ‹è¯•å•ä¸ªRSSæ¡ç›®çš„æ¶ˆæ¯æ ¼å¼"""
    user = update.message.from_user
    chat_id = update.message.chat_id
    logging.info(f"æ”¶åˆ°SHOWå‘½ä»¤ - ç”¨æˆ·: {user.username}(ID:{user.id}) èŠå¤©ID: {chat_id}")

    if not context.args:
        await update.message.reply_text(
            "ğŸ”§ å¼€å‘è€…è°ƒè¯•å‘½ä»¤\n\n"
            "ç”¨æ³•ï¼š/show [type] <item_xml>\n\n"
            "å‚æ•°è¯´æ˜ï¼š\n"
            "â€¢ type: æ¶ˆæ¯ç±»å‹ (å¯é€‰)\n"
            "  - auto: è‡ªåŠ¨åˆ¤æ–­ (é»˜è®¤)\n"
            "  - text: å¼ºåˆ¶æ–‡å­—ä¸ºä¸»æ¨¡å¼\n"
            "  - media: å¼ºåˆ¶å›¾ç‰‡ä¸ºä¸»æ¨¡å¼\n\n"
            "æ”¯æŒæ ¼å¼ï¼š\n"
            "â€¢ RSS 2.0: <item>...</item>\n"
            "â€¢ Atom 1.0: <entry>...</entry>\n\n"
            "ç¤ºä¾‹ï¼š\n"
            "RSSæ ¼å¼ï¼š\n"
            "/show <item><title>æ ‡é¢˜</title><description>æè¿°</description></item>\n\n"
            "Atomæ ¼å¼ï¼š\n"
            "/show <entry><title>æ ‡é¢˜</title><content>å†…å®¹</content></entry>\n\n"
            "å¼ºåˆ¶æ¨¡å¼ï¼š\n"
            "/show text <entry><title>æ ‡é¢˜</title></entry>\n"
            "/show media <item><title>æ ‡é¢˜</title></item>"
        )
        return

    # è§£æå‚æ•°ï¼šæ£€æŸ¥ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯å¦æ˜¯type
    message_type = "auto"  # é»˜è®¤å€¼
    xml_start_index = 0

    # æ£€æŸ¥ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯å¦æ˜¯æœ‰æ•ˆçš„type
    if len(context.args) > 0 and context.args[0].lower() in ['auto', 'text', 'media']:
        message_type = context.args[0].lower()
        xml_start_index = 1
        logging.info(f"SHOWå‘½ä»¤æŒ‡å®šæ¶ˆæ¯ç±»å‹: {message_type}")
    else:
        logging.info(f"SHOWå‘½ä»¤ä½¿ç”¨é»˜è®¤æ¶ˆæ¯ç±»å‹: {message_type}")

    # è·å–å®Œæ•´çš„æ¶ˆæ¯æ–‡æœ¬ï¼Œå»æ‰å‘½ä»¤éƒ¨åˆ†
    full_text = update.message.text
    if full_text.startswith('/show '):
        remaining_text = full_text[6:]  # å»æ‰ "/show " å‰ç¼€

        # å¦‚æœæŒ‡å®šäº†typeï¼Œéœ€è¦å»æ‰typeå‚æ•°
        if xml_start_index == 1:
            # æ‰¾åˆ°ç¬¬ä¸€ä¸ªç©ºæ ¼åçš„å†…å®¹ä½œä¸ºXML
            parts = remaining_text.split(' ', 1)
            if len(parts) > 1:
                item_xml = parts[1]
            else:
                await update.message.reply_text(
                    f"âŒ æŒ‡å®šäº†æ¶ˆæ¯ç±»å‹ '{message_type}' ä½†ç¼ºå°‘XMLå†…å®¹\n"
                    f"ç”¨æ³•ï¼š/show {message_type} <item_xml>"
                )
                return
        else:
            item_xml = remaining_text
    else:
        await update.message.reply_text("âŒ æ— æ³•è§£æå‘½ä»¤å‚æ•°")
        return

    # éªŒè¯XMLå†…å®¹ä¸ä¸ºç©º
    if not item_xml.strip():
        await update.message.reply_text(
            "âŒ XMLå†…å®¹ä¸ºç©º\n"
            "è¯·æä¾›æœ‰æ•ˆçš„RSSæ¡ç›®XMLå†…å®¹"
        )
        return

    try:
        # æ™ºèƒ½è¯†åˆ«å¹¶å¤„ç†RSSå’ŒAtomæ ¼å¼
        item_xml_stripped = item_xml.strip()

        # æ£€æŸ¥æ˜¯å¦å·²ç»æ˜¯å®Œæ•´çš„æ¡ç›®æ ‡ç­¾
        if not (item_xml_stripped.startswith('<item') or item_xml_stripped.startswith('<entry')):
            # å¦‚æœæ²¡æœ‰æ¡ç›®æ ‡ç­¾ï¼Œé»˜è®¤åŒ…è£…ä¸ºitemæ ‡ç­¾ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
            item_xml = f"<item>{item_xml}</item>"
            logging.info("è‡ªåŠ¨åŒ…è£…ä¸ºRSS itemæ ‡ç­¾")
        else:
            logging.info(f"æ£€æµ‹åˆ°å®Œæ•´çš„æ¡ç›®æ ‡ç­¾: {item_xml_stripped[:20]}...")

        # æ·»åŠ è°ƒè¯•æ—¥å¿—
        logging.info(f"SHOWå‘½ä»¤æ¥æ”¶åˆ°çš„XMLå†…å®¹é•¿åº¦: {len(item_xml)} å­—ç¬¦")
        logging.debug(f"SHOWå‘½ä»¤åŸå§‹å†…å®¹: {item_xml[:500]}...")

        # ç›´æ¥ä½¿ç”¨BeautifulSoupè§£æï¼Œè·³è¿‡XMLè§£æ
        try:
            from bs4 import BeautifulSoup
        except ImportError:
            await update.message.reply_text(
                "âŒ ç³»ç»Ÿé”™è¯¯ï¼šBeautifulSoupæœªå®‰è£…\n"
                "è¯·è”ç³»ç®¡ç†å‘˜å®‰è£…ä¾èµ–ï¼špip install beautifulsoup4"
            )
            logging.error("BeautifulSoupæœªå®‰è£…ï¼Œæ— æ³•è§£æRSSå†…å®¹")
            return

        # ä½¿ç”¨BeautifulSoupè§£æï¼ˆä¼˜å…ˆxmlè§£æå™¨ï¼Œå¤±è´¥åˆ™ç”¨html.parserï¼‰
        try:
            soup = BeautifulSoup(item_xml, 'xml')
            logging.info("ä½¿ç”¨XMLè§£æå™¨æˆåŠŸè§£æå†…å®¹")
        except Exception as xml_error:
            logging.warning(f"XMLè§£æå™¨å¤±è´¥: {str(xml_error)}, å°è¯•HTMLè§£æå™¨")
            soup = BeautifulSoup(item_xml, 'html.parser')
            logging.info("ä½¿ç”¨HTMLè§£æå™¨æˆåŠŸè§£æå†…å®¹")

        # æå–å„ä¸ªå­—æ®µ
        mock_entry = {
            'title': 'æ— æ ‡é¢˜',
            'description': '',
            'summary': '',
            'link': '',
            'published': '',
            'author': '',
            'id': ''
        }

        # æå–æ ‡é¢˜
        if soup.title:
            mock_entry['title'] = soup.title.get_text().strip()

        # æå–æè¿°ï¼ˆæ”¯æŒRSSçš„descriptionå’ŒAtomçš„contentï¼‰
        # ä¼˜å…ˆä½¿ç”¨contentæ ‡ç­¾ï¼ˆAtomæ ¼å¼ï¼‰ï¼Œå…¶æ¬¡ä½¿ç”¨descriptionæ ‡ç­¾ï¼ˆRSSæ ¼å¼ï¼‰
        content_tag = soup.find('content') or soup.find('description')
        if content_tag:
            # è·å–æ ‡ç­¾çš„å†…éƒ¨HTMLå†…å®¹
            desc_content = content_tag.decode_contents() if content_tag.contents else content_tag.get_text()
            mock_entry['description'] = desc_content.strip()
            mock_entry['summary'] = mock_entry['description']

        # æå–é“¾æ¥ï¼ˆæ”¯æŒAtomçš„linkæ ‡ç­¾å’ŒRSSçš„linkæ ‡ç­¾ï¼‰
        link_tag = soup.find('link')
        if link_tag:
            # Atomæ ¼å¼çš„linkæ ‡ç­¾å¯èƒ½æœ‰hrefå±æ€§
            if link_tag.get('href'):
                mock_entry['link'] = link_tag.get('href').strip()
            # RSSæ ¼å¼çš„linkæ ‡ç­¾ç›´æ¥åŒ…å«URLæ–‡æœ¬
            elif link_tag.get_text():
                mock_entry['link'] = link_tag.get_text().strip()

        # æå–å‘å¸ƒæ—¶é—´ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
        # RSS: pubDate, Atom: published, updated
        pubdate_tag = (soup.find('pubDate') or soup.find('pubdate') or
                      soup.find('published') or soup.find('updated'))
        if pubdate_tag:
            mock_entry['published'] = pubdate_tag.get_text().strip()

        # æå–ä½œè€…ï¼ˆæ”¯æŒAtomçš„author/nameå’ŒRSSçš„authorï¼‰
        author_tag = soup.find('author')
        if author_tag:
            # Atomæ ¼å¼å¯èƒ½æœ‰nameå­æ ‡ç­¾
            name_tag = author_tag.find('name')
            if name_tag:
                mock_entry['author'] = name_tag.get_text().strip()
            else:
                mock_entry['author'] = author_tag.get_text().strip()

        # æå–IDï¼ˆæ”¯æŒAtomçš„idå’ŒRSSçš„guidï¼‰
        id_tag = soup.find('id') or soup.find('guid')
        if id_tag:
            mock_entry['id'] = id_tag.get_text().strip()

        # æ£€æµ‹æ ¼å¼ç±»å‹
        format_type = "Atom" if item_xml_stripped.startswith('<entry') else "RSS"
        logging.info(f"æ£€æµ‹åˆ°æ ¼å¼ç±»å‹: {format_type}")
        logging.info(f"BeautifulSoupè§£ææˆåŠŸï¼Œæå–åˆ°æ ‡é¢˜: {mock_entry['title']}")

        # ä½¿ç”¨ç»Ÿä¸€çš„æ¡ç›®ä¿¡æ¯æå–å‡½æ•°ï¼ˆæ‰‹åŠ¨è§£ææ¨¡å¼ï¼‰
        entry_info = extract_entry_info(mock_entry, is_feedparser_entry=False)

        # æ·»åŠ æ ¼å¼ç±»å‹åˆ°entry_infoä¸­
        entry_info['format_type'] = format_type

        # ä½¿ç”¨ç»Ÿä¸€çš„å‘é€å‡½æ•°ï¼Œå¹¶æ˜¾ç¤ºåˆ†æä¿¡æ¯
        await send_entry_unified_with_analysis(
            context.bot,
            chat_id,
            entry_info,
            message_type=message_type,
            update=update
        )

        logging.info(f"SHOWå‘½ä»¤æ‰§è¡ŒæˆåŠŸï¼Œå·²å‘é€æ¡ç›®: {entry_info.get('title', 'Unknown')}, æ¨¡å¼: {message_type}")

    except Exception as e:
        await update.message.reply_text(f"âŒ å¤„ç†å¤±è´¥: {str(e)}")
        logging.error(f"SHOWå‘½ä»¤æ‰§è¡Œå¤±è´¥: {str(e)}", exc_info=True)


async def send_entry_unified_with_analysis(
    bot: Bot,
    chat_id: str,
    entry_info: dict,
    message_type: str = "auto",
    update: Update = None
) -> None:
    """
    å¸¦åˆ†æä¿¡æ¯çš„ç»Ÿä¸€æ¡ç›®å‘é€å‡½æ•°ï¼ˆä¸“ç”¨äºshowå‘½ä»¤ï¼‰

    Args:
        bot: Telegram Botå®ä¾‹
        chat_id: ç›®æ ‡èŠå¤©ID
        entry_info: æ ‡å‡†åŒ–çš„æ¡ç›®ä¿¡æ¯å­—å…¸
        message_type: æ¶ˆæ¯ç±»å‹ ("auto", "text", "media")
        update: Updateå¯¹è±¡ï¼ˆç”¨äºå›å¤æ¶ˆæ¯ï¼‰
    """
    try:
        title = entry_info['title']
        link = entry_info['link']
        content = entry_info['content']
        published_time = entry_info['published']
        author = entry_info['author']
        format_type = entry_info.get('format_type', 'Unknown')

        logging.info(f"å¼€å§‹å‘é€æ¡ç›®: '{title}'")

        # ä½¿ç”¨å…¬å…±å‡½æ•°æå–å›¾ç‰‡
        images = extract_and_clean_images(content)

        # æ ¹æ®message_typeå‚æ•°å†³å®šæ¶ˆæ¯æ¨¡å¼
        if message_type == "auto":
            # è‡ªåŠ¨åˆ¤æ–­æ¨¡å¼
            is_image_focused = len(images) >= 2
            mode = "å›¾ç‰‡ä¸ºä¸»" if is_image_focused else "æ–‡å­—ä¸ºä¸»"
            mode_reason = f"è‡ªåŠ¨åˆ¤æ–­({len(images)}å¼ å›¾ç‰‡)"
        elif message_type == "text":
            # å¼ºåˆ¶æ–‡å­—ä¸ºä¸»æ¨¡å¼
            is_image_focused = False
            mode = "æ–‡å­—ä¸ºä¸»"
            mode_reason = "å¼ºåˆ¶æŒ‡å®š"
        elif message_type == "media":
            # å¼ºåˆ¶å›¾ç‰‡ä¸ºä¸»æ¨¡å¼
            is_image_focused = True
            mode = "å›¾ç‰‡ä¸ºä¸»"
            mode_reason = "å¼ºåˆ¶æŒ‡å®š"
        else:
            # é»˜è®¤è‡ªåŠ¨åˆ¤æ–­
            is_image_focused = len(images) >= 2
            mode = "å›¾ç‰‡ä¸ºä¸»" if is_image_focused else "æ–‡å­—ä¸ºä¸»"
            mode_reason = f"é»˜è®¤åˆ¤æ–­({len(images)}å¼ å›¾ç‰‡)"

        logging.info(f"SHOWå‘½ä»¤æ¶ˆæ¯æ¨¡å¼: {mode} ({mode_reason})")

        # å‘é€åˆ†æä¿¡æ¯
        analysis_message = (
            f"ğŸ”§ SHOWå‘½ä»¤åˆ†æç»“æœï¼š\n"
            f"------------------------------------\n"
            f"ğŸ“‹ æ ¼å¼ç±»å‹: {format_type}\n"
            f"ğŸ“° æ ‡é¢˜: {title}\n"
            f"ğŸ‘¤ ä½œè€…: {author or 'æ— '}\n"
            f"ğŸ”— é“¾æ¥: {link[:50]}{'...' if len(link) > 50 else ''}\n"
            f"ğŸ•’ æ—¶é—´: {published_time or 'æ— '}\n"
            f"ğŸ–¼ï¸ å›¾ç‰‡æ•°é‡: {len(images)}\n"
            f"âš™ï¸ æŒ‡å®šç±»å‹: {message_type}\n"
            f"ğŸ“Š å®é™…æ¨¡å¼: {mode} ({mode_reason})\n"
            f"------------------------------------\n"
            f"æ­£åœ¨å‘é€å®é™…æ¶ˆæ¯..."
        )

        if update:
            await update.message.reply_text(analysis_message)
        else:
            await bot.send_message(chat_id=chat_id, text=analysis_message)

        # æ ¹æ®æ¨¡å¼å‘é€æ¶ˆæ¯
        logging.info(f"SHOWå‘½ä»¤å¼€å§‹å‘é€æ¶ˆæ¯ï¼Œæ¨¡å¼: {mode}")

        if is_image_focused:
            # å›¾ç‰‡ä¸ºä¸»æ¨¡å¼ï¼šåªå‘é€å›¾ç‰‡ç»„ï¼ˆå¸¦ç®€æ´captionï¼‰
            if images:
                await send_image_groups_with_caption(bot, chat_id, title, author, images)
            else:
                # å¦‚æœå¼ºåˆ¶æŒ‡å®šmediaæ¨¡å¼ä½†æ²¡æœ‰å›¾ç‰‡ï¼Œå‘é€æç¤º
                if message_type == "media":
                    if update:
                        await update.message.reply_text("âš ï¸ å¼ºåˆ¶æŒ‡å®šå›¾ç‰‡ä¸ºä¸»æ¨¡å¼ï¼Œä½†æœªæ‰¾åˆ°å›¾ç‰‡å†…å®¹")
                    else:
                        await bot.send_message(chat_id=chat_id, text="âš ï¸ å¼ºåˆ¶æŒ‡å®šå›¾ç‰‡ä¸ºä¸»æ¨¡å¼ï¼Œä½†æœªæ‰¾åˆ°å›¾ç‰‡å†…å®¹")
        else:
            # æ–‡å­—ä¸ºä¸»æ¨¡å¼ï¼šå…ˆå‘é€æ–‡å­—æ¶ˆæ¯ï¼Œå†å‘é€å›¾ç‰‡ç»„
            await send_text_message(bot, chat_id, title, link, content, published_time)

            # å¦‚æœæœ‰å›¾ç‰‡ï¼Œå‘é€å›¾ç‰‡ç»„ï¼ˆå¸¦ç®€æ´captionï¼‰
            if images:
                await asyncio.sleep(3)  # å»¶è¿Ÿé¿å…flood control
                await send_image_groups_with_caption(bot, chat_id, title, author, images)

        logging.info(f"âœ… SHOWå‘½ä»¤æ¡ç›®å‘é€å®Œæˆ: '{title}' ({mode})")

    except Exception as e:
        logging.error(f"âŒ SHOWå‘½ä»¤å‘é€æ¡ç›®å¤±è´¥: '{entry_info.get('title', 'Unknown')}', é”™è¯¯: {str(e)}")
        raise
