"""
RSSæ¶ˆæ¯å‘é€æ¨¡å—
è´Ÿè´£å¤„ç†æ‰€æœ‰ä¸æ¶ˆæ¯å‘é€ç›¸å…³çš„åŠŸèƒ½
"""

import logging
import asyncio
import re
from telegram import Bot, InputMediaPhoto
from datetime import datetime
from urllib.parse import urlparse
from .media_strategy import create_media_strategy_manager, MediaInfo


class MediaAccessError(Exception):
    """åª’ä½“æ— æ³•è®¿é—®å¼‚å¸¸"""
    pass


def extract_and_clean_media(content: str) -> list[dict]:
    """
    æå–å¹¶æ¸…ç†åª’ä½“URLï¼ˆåŒ…æ‹¬å›¾ç‰‡å’Œè§†é¢‘ï¼‰ï¼Œè¿”å›åŒ…å«ç±»å‹ä¿¡æ¯çš„åª’ä½“åˆ—è¡¨

    Args:
        content: HTMLå†…å®¹

    Returns:
        list[dict]: åª’ä½“ä¿¡æ¯åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« {'url': str, 'type': str}
                   type å¯èƒ½æ˜¯ 'image' æˆ– 'video'
    """
    media_list = []
    if not content:
        return media_list

    # æå–å›¾ç‰‡URL
    img_pattern = r'<img[^>]+src=["\']([^"\']+)["\'][^>]*>'
    raw_images = re.findall(img_pattern, content, re.IGNORECASE)
    logging.info(f"æå–åˆ° {len(raw_images)} å¼ åŸå§‹å›¾ç‰‡")

    # æå–è§†é¢‘URL
    video_pattern = r'<video[^>]+src=["\']([^"\']+)["\'][^>]*>'
    raw_videos = re.findall(video_pattern, content, re.IGNORECASE)
    logging.info(f"æå–åˆ° {len(raw_videos)} ä¸ªåŸå§‹è§†é¢‘")

    # å¤„ç†å›¾ç‰‡
    for img_url in raw_images:
        # æ¸…ç†HTMLå®ä½“ç¼–ç 
        clean_url = img_url.replace('&amp;', '&').replace('&lt;', '<').replace('&gt;', '>')
        clean_url = clean_url.replace('&quot;', '"').strip()

        # è¿‡æ»¤æ‰æ˜æ˜¾çš„å°å›¾æ ‡å’Œè£…é¥°å›¾ç‰‡
        if any(keyword in clean_url.lower() for keyword in ['icon', 'logo', 'avatar', 'emoji', 'button']):
            logging.debug(f"è¿‡æ»¤è£…é¥°å›¾ç‰‡: {clean_url}")
            continue

        # éªŒè¯URLæ ¼å¼
        if clean_url.startswith(('http://', 'https://')):
            media_list.append({'url': clean_url, 'type': 'image'})
            logging.debug(f"æ·»åŠ æœ‰æ•ˆå›¾ç‰‡: {clean_url}")
        else:
            logging.warning(f"è·³è¿‡æ— æ•ˆå›¾ç‰‡URL: {clean_url}")

    # å¤„ç†è§†é¢‘
    for video_url in raw_videos:
        # æ¸…ç†HTMLå®ä½“ç¼–ç 
        clean_url = video_url.replace('&amp;', '&').replace('&lt;', '<').replace('&gt;', '>')
        clean_url = clean_url.replace('&quot;', '"').strip()

        # éªŒè¯URLæ ¼å¼
        if clean_url.startswith(('http://', 'https://')):
            media_list.append({'url': clean_url, 'type': 'video'})
            logging.debug(f"æ·»åŠ æœ‰æ•ˆè§†é¢‘: {clean_url}")
        else:
            logging.warning(f"è·³è¿‡æ— æ•ˆè§†é¢‘URL: {clean_url}")

    logging.info(f"æ¸…ç†åæœ‰æ•ˆåª’ä½“æ•°é‡: {len(media_list)} (å›¾ç‰‡: {len(raw_images)}, è§†é¢‘: {len(raw_videos)})")

    # è®°å½•å‰å‡ ä¸ªåª’ä½“URLç”¨äºè°ƒè¯•
    for i, media_info in enumerate(media_list[:3], 1):
        media_type = "å›¾ç‰‡" if media_info['type'] == 'image' else "è§†é¢‘"
        logging.info(f"åª’ä½“{i}({media_type}): {media_info['url']}")

    return media_list


def calculate_balanced_batches(total_images: int, max_per_batch: int = 10) -> list[int]:
    """
    è®¡ç®—å‡è¡¡çš„å›¾ç‰‡åˆ†æ‰¹æ–¹æ¡ˆ

    Args:
        total_images: æ€»å›¾ç‰‡æ•°é‡
        max_per_batch: æ¯æ‰¹æœ€å¤§å›¾ç‰‡æ•°é‡

    Returns:
        list[int]: æ¯æ‰¹çš„å›¾ç‰‡æ•°é‡åˆ—è¡¨
    """
    if total_images <= max_per_batch:
        return [total_images]

    # è®¡ç®—éœ€è¦å¤šå°‘æ‰¹
    num_batches = (total_images + max_per_batch - 1) // max_per_batch

    # è®¡ç®—åŸºç¡€æ¯æ‰¹æ•°é‡
    base_size = total_images // num_batches
    remainder = total_images % num_batches

    # æ„å»ºåˆ†æ‰¹æ–¹æ¡ˆï¼šå‰remainderæ‰¹å¤š1å¼ ï¼Œåé¢çš„æ‰¹æ¬¡ä¸ºbase_size
    batch_sizes = []
    for i in range(num_batches):
        if i < remainder:
            batch_sizes.append(base_size + 1)
        else:
            batch_sizes.append(base_size)

    logging.info(f"å‡è¡¡åˆ†æ‰¹æ–¹æ¡ˆ: æ€»æ•°{total_images}, åˆ†{num_batches}æ‰¹, æ–¹æ¡ˆ{batch_sizes}")
    return batch_sizes


async def send_media_groups_with_caption(
    bot: Bot,
    chat_id: str,
    title: str,
    author: str,
    media_list: list[dict],
    full_caption: str = None
) -> None:
    """
    å‘é€åª’ä½“ç»„ï¼ˆå›¾ç‰‡å’Œè§†é¢‘ï¼‰ï¼Œä½¿ç”¨æ–°çš„åª’ä½“ç­–ç•¥ç³»ç»Ÿ
    ç­–ç•¥ä¼˜å…ˆçº§ï¼š
    1. URLç›´æ¥å‘é€ï¼ˆå°äºé˜ˆå€¼çš„æ–‡ä»¶ï¼‰
    2. ä¸‹è½½åä¸Šä¼ ï¼ˆå¤§æ–‡ä»¶æˆ–URLå‘é€å¤±è´¥ï¼‰
    3. æ–‡æœ¬é™çº§ï¼ˆåª’ä½“å‘é€å®Œå…¨å¤±è´¥ï¼‰

    Args:
        bot: Telegram Botå®ä¾‹
        chat_id: ç›®æ ‡èŠå¤©ID
        title: æ ‡é¢˜
        author: ä½œè€…
        media_list: åª’ä½“ä¿¡æ¯åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« {'url': str, 'type': str}
        full_caption: å®Œæ•´çš„captionå†…å®¹ï¼ˆå¯é€‰ï¼Œå¦‚æœæä¾›åˆ™ä½¿ç”¨å®Œæ•´æ ¼å¼ï¼‰

    Raises:
        MediaAccessError: å½“åª’ä½“æ— æ³•è®¿é—®æ—¶æŠ›å‡ºï¼Œè°ƒç”¨æ–¹å¯ä»¥é™çº§åˆ°æ–‡å­—æ¨¡å¼
    """
    if not media_list:
        logging.warning("send_media_groups_with_caption: æ²¡æœ‰åª’ä½“å¯å‘é€")
        return

    logging.info(f"ğŸ¯ å¯ç”¨æ–°åª’ä½“ç­–ç•¥ç³»ç»Ÿå‘é€: {len(media_list)} ä¸ªåª’ä½“æ–‡ä»¶")

    # åˆ›å»ºåª’ä½“ç­–ç•¥ç®¡ç†å™¨å’Œå‘é€å™¨
    strategy_manager, media_sender = create_media_strategy_manager(bot)

    # åˆ†æåª’ä½“æ–‡ä»¶ï¼Œç¡®å®šå‘é€ç­–ç•¥
    analyzed_media = strategy_manager.analyze_media_files(media_list)

    # æ£€æŸ¥æ˜¯å¦æœ‰å¯å‘é€çš„åª’ä½“
    sendable_media = [m for m in analyzed_media if m.send_strategy.value != 'text_fallback']
    if not sendable_media:
        logging.error("âŒ æ‰€æœ‰åª’ä½“æ–‡ä»¶éƒ½æ— æ³•å‘é€ï¼ŒæŠ›å‡ºMediaAccessError")
        raise MediaAccessError("æ‰€æœ‰åª’ä½“æ–‡ä»¶éƒ½æ— æ³•è®¿é—®")

    # åˆ¤æ–­ä½¿ç”¨å“ªç§captionæ ¼å¼
    use_full_caption = full_caption is not None

    if use_full_caption:
        logging.info(f"ğŸ“ ä½¿ç”¨å®Œæ•´captionæ ¼å¼: é•¿åº¦={len(full_caption)}")
        # ç¡®ä¿captionä¸è¶…è¿‡Telegramé™åˆ¶ï¼ˆ1024å­—ç¬¦ï¼‰
        max_caption_length = 1024
        if len(full_caption) > max_caption_length:
            full_caption = full_caption[:max_caption_length-3] + "..."
            logging.info(f"Captionè¿‡é•¿å·²æˆªæ–­åˆ° {len(full_caption)} å­—ç¬¦")
    else:
        logging.info(f"ğŸ“ ä½¿ç”¨ç®€æ´captionæ ¼å¼: æ ‡é¢˜='{title}', ä½œè€…='{author}'")
        # æˆªæ–­æ ‡é¢˜ï¼ˆTelegram captioné™åˆ¶1024å­—ç¬¦ï¼‰
        max_title_length = 100
        original_title = title
        if len(title) > max_title_length:
            title = title[:max_title_length] + "..."
            logging.info(f"æ ‡é¢˜è¿‡é•¿å·²æˆªæ–­: '{original_title}' -> '{title}'")

    # è®¡ç®—å‡è¡¡çš„åˆ†æ‰¹æ–¹æ¡ˆï¼ˆæ¯æ‰¹æœ€å¤š10ä¸ªåª’ä½“ï¼‰
    batch_sizes = calculate_balanced_batches(len(sendable_media), max_per_batch=10)
    total_batches = len(batch_sizes)

    logging.info(f"ğŸ“¦ åˆ†æ‰¹å‘é€æ–¹æ¡ˆ: {total_batches} æ‰¹ï¼Œåˆ†æ‰¹å¤§å°: {batch_sizes}")

    # è®°å½•æ˜¯å¦æœ‰ä»»ä½•æ‰¹æ¬¡å‘é€æˆåŠŸ
    any_batch_success = False
    media_access_errors = []

    # æŒ‰ç…§åˆ†æ‰¹æ–¹æ¡ˆå‘é€åª’ä½“
    media_index = 0
    for batch_num, batch_size in enumerate(batch_sizes, 1):
        # è·å–å½“å‰æ‰¹æ¬¡çš„åª’ä½“
        batch_media = sendable_media[media_index:media_index + batch_size]
        media_index += batch_size

        logging.info(f"ğŸ“¤ å‡†å¤‡å‘é€ç¬¬ {batch_num}/{total_batches} æ‰¹ï¼ŒåŒ…å« {batch_size} ä¸ªåª’ä½“")

        # æ„å»ºcaption
        if use_full_caption:
            # å®Œæ•´captionæ ¼å¼
            if batch_num == 1:
                # ç¬¬ä¸€æ‰¹ï¼šä½¿ç”¨å®Œæ•´caption
                if total_batches > 1:
                    # å¦‚æœæœ‰å¤šæ‰¹ï¼Œåœ¨ç¬¬ä¸€æ‰¹captionåæ·»åŠ æ‰¹æ¬¡ä¿¡æ¯
                    caption = f"{full_caption}\n\n {batch_num}/{total_batches}"
                else:
                    # åªæœ‰ä¸€æ‰¹ï¼Œç›´æ¥ä½¿ç”¨å®Œæ•´caption
                    caption = full_caption
            else:
                # åç»­æ‰¹æ¬¡ï¼šåªæ˜¾ç¤ºæ‰¹æ¬¡ä¿¡æ¯
                caption = f" {batch_num}/{total_batches}"
        else:
            # ç®€æ´captionæ ¼å¼ï¼š#ä½œè€… + title + æ‰¹æ¬¡ä¿¡æ¯
            caption_parts = []

            # æ·»åŠ ä½œè€…ï¼ˆå¦‚æœæœ‰ï¼‰
            if author:
                caption_parts.append(f"#{author}")
                logging.debug(f"æ·»åŠ ä½œè€…æ ‡ç­¾: #{author}")

            # æ·»åŠ æ ‡é¢˜
            caption_parts.append(title)

            # åªåœ¨å¤šæ‰¹æ¬¡æ—¶æ˜¾ç¤ºæ‰¹æ¬¡ä¿¡æ¯
            if total_batches > 1:
                batch_info = f"{batch_num}/{total_batches}"
                caption_parts.append(batch_info)
                logging.debug(f"æ·»åŠ æ‰¹æ¬¡ä¿¡æ¯: {batch_info}")

            caption = " ".join(caption_parts)

        logging.info(f"ğŸ“ ç¬¬ {batch_num} æ‰¹caption: '{caption}' (é•¿åº¦: {len(caption)})")

        try:
            # ä½¿ç”¨æ–°çš„åª’ä½“ç­–ç•¥ç³»ç»Ÿå‘é€
            success = await media_sender.send_media_group_with_strategy(
                chat_id=chat_id,
                media_list=batch_media,
                caption=caption
            )

            if success:
                logging.info(f"âœ… ç¬¬ {batch_num}/{total_batches} æ‰¹åª’ä½“ç»„å‘é€æˆåŠŸ ({batch_size}ä¸ªåª’ä½“)")
                any_batch_success = True
            else:
                logging.error(f"âŒ ç¬¬ {batch_num}/{total_batches} æ‰¹åª’ä½“ç»„å‘é€å¤±è´¥")
                media_access_errors.append(f"æ‰¹æ¬¡{batch_num}: ç­–ç•¥å‘é€å¤±è´¥")

        except Exception as e:
            logging.error(f"âŒ å‘é€ç¬¬ {batch_num} æ‰¹åª’ä½“ç»„å¼‚å¸¸: {str(e)}", exc_info=True)
            media_access_errors.append(f"æ‰¹æ¬¡{batch_num}: {str(e)}")

    # æ£€æŸ¥å‘é€ç»“æœ
    if not any_batch_success:
        logging.error("âŒ æ‰€æœ‰æ‰¹æ¬¡éƒ½å‘é€å¤±è´¥ï¼ŒæŠ›å‡ºMediaAccessError")
        error_summary = "; ".join(media_access_errors)
        raise MediaAccessError(f"æ‰€æœ‰åª’ä½“æ‰¹æ¬¡å‘é€å¤±è´¥: {error_summary}")
    elif media_access_errors:
        logging.warning(f"âš ï¸ éƒ¨åˆ†æ‰¹æ¬¡å‘é€å¤±è´¥: {'; '.join(media_access_errors)}")
    else:
        logging.info(f"ğŸ‰ æ‰€æœ‰ {total_batches} æ‰¹åª’ä½“ç»„å‘é€æˆåŠŸï¼")


async def send_text_message(
    bot: Bot,
    chat_id: str,
    title: str,
    link: str,
    content: str,
    published_time: str
) -> None:
    """
    å‘é€çº¯æ–‡å­—æ¶ˆæ¯ï¼ˆæ–‡å­—ä¸ºä¸»æ¨¡å¼ï¼‰
    """
    try:
        # æ„å»ºæ¶ˆæ¯å†…å®¹
        message_parts = []

        # æ·»åŠ æ ‡é¢˜
        if title:
            message_parts.append(f"ğŸ“° {title}")

        # æ·»åŠ å†…å®¹ï¼ˆé™åˆ¶é•¿åº¦ï¼‰
        if content:
            # æ¸…ç†HTMLæ ‡ç­¾
            clean_content = re.sub(r'<[^>]+>', '', content)
            clean_content = clean_content.replace('&nbsp;', ' ').replace('&amp;', '&')
            clean_content = clean_content.replace('&lt;', '<').replace('&gt;', '>')
            clean_content = clean_content.replace('&quot;', '"').strip()

            # é™åˆ¶å†…å®¹é•¿åº¦
            max_content_length = 500
            if len(clean_content) > max_content_length:
                clean_content = clean_content[:max_content_length] + "..."

            if clean_content:
                message_parts.append(f"\n{clean_content}")

        # æ·»åŠ å‘å¸ƒæ—¶é—´
        if published_time:
            message_parts.append(f"\nâ° {published_time}")

        # æ·»åŠ é“¾æ¥
        if link:
            message_parts.append(f"\nğŸ”— {link}")

        message = "".join(message_parts)

        # å‘é€æ¶ˆæ¯
        await bot.send_message(chat_id=chat_id, text=message)
        logging.info(f"âœ… æ–‡å­—æ¶ˆæ¯å‘é€æˆåŠŸ: '{title}'")

    except Exception as e:
        logging.error(f"âŒ å‘é€æ–‡å­—æ¶ˆæ¯å¤±è´¥: '{title}', é”™è¯¯: {str(e)}", exc_info=True)
        raise


async def send_update_notification(
    bot: Bot,
    url: str,
    new_entries: list[dict],
    xml_content: str | None,
    target_chat: str = None,
) -> None:
    """
    å‘é€Feedæ›´æ–°é€šçŸ¥ï¼ŒåŒ…æ‹¬æ–°å¢æ¡ç›®åˆ—è¡¨ã€‚
    ä½¿ç”¨æ™ºèƒ½æ¶ˆæ¯å‘é€ï¼š
    - å›¾ç‰‡ä¸ºä¸»æ¨¡å¼ï¼ˆâ‰¥2å¼ å›¾ç‰‡ï¼‰ï¼šåª’ä½“ç»„ + ç®€æ´caption
    - æ–‡å­—ä¸ºä¸»æ¨¡å¼ï¼ˆ<2å¼ å›¾ç‰‡ï¼‰ï¼šå®Œæ•´æ–‡å­—å†…å®¹ + å›¾ç‰‡è¡¥å……
    - æ”¯æŒå‡è¡¡åˆ†æ‰¹ï¼Œæ¯æ‰¹æœ€å¤š10å¼ å›¾ç‰‡ï¼Œåˆ†å¸ƒæ›´å‡åŒ€
    """
    from core.config import telegram_config
    from .entry_processor import process_and_send_entry

    chat_id = target_chat or telegram_config["target_chat"]
    if not chat_id:
        logging.error("æœªé…ç½®å‘é€ç›®æ ‡ï¼Œè¯·æ£€æŸ¥TELEGRAM_TARGET_CHATç¯å¢ƒå˜é‡")
        return

    domain = urlparse(url).netloc

    try:
        # åªå‘é€æ¡ç›®å†…å®¹ï¼Œä¸å‘é€å¼€å§‹å’Œç»“æŸé€šçŸ¥
        if new_entries:
            logging.info(f"å¼€å§‹å‘é€ {len(new_entries)} ä¸ªæ¡ç›® for {domain}")

            for i, entry in enumerate(new_entries, 1):
                try:
                    # å‘é€æ¡ç›®æ¶ˆæ¯ï¼ˆåŒ…å«å›¾ç‰‡ï¼‰
                    await process_and_send_entry(bot, chat_id, entry, i, len(new_entries))
                    logging.info(f"å·²å‘é€æ¡ç›®: {entry.get('title', 'Unknown')}")

                    # æ§åˆ¶å‘é€é€Ÿåº¦ï¼Œé¿å…flood exceed
                    # Telegramé™åˆ¶ï¼šåŒä¸€èŠå¤©æ¯ç§’æœ€å¤š1æ¡æ¶ˆæ¯ï¼Œæ¯åˆ†é’Ÿæœ€å¤š20æ¡æ¶ˆæ¯
                    if i % 10 == 0:  # æ¯10æ¡æ¶ˆæ¯æš‚åœ1åˆ†é’Ÿ
                        logging.info(f"å·²å‘é€10æ¡æ¶ˆæ¯ï¼Œæš‚åœ60ç§’é¿å…flood exceed...")
                        await asyncio.sleep(60)
                    else:
                        # æ¯æ¡æ¶ˆæ¯é—´éš”8ç§’ï¼Œç¡®ä¿ä¸ä¼šè§¦å‘flood control
                        logging.debug(f"ç­‰å¾…8ç§’åå‘é€ä¸‹ä¸€æ¡ç›®...")
                        await asyncio.sleep(8)

                except Exception as e:
                    logging.error(f"å‘é€æ¡ç›®å¤±è´¥: {entry.get('title', 'Unknown')}, é”™è¯¯: {str(e)}", exc_info=True)
                    # å‡ºé”™åä¹Ÿè¦ç­‰å¾…ï¼Œé¿å…è¿ç»­é”™è¯¯
                    await asyncio.sleep(5)
                    continue

            logging.info(f"å·²å‘é€ {len(new_entries)} ä¸ªæ¡ç›® for {domain}")
        else:
            logging.info(f"{domain} æ— æ–°å¢å†…å®¹ï¼Œè·³è¿‡å‘é€")
    except Exception as e:
        logging.error(f"å‘é€Feedæ›´æ–°æ¶ˆæ¯å¤±è´¥ for {url}: {str(e)}", exc_info=True)