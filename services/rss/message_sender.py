"""
RSSæ¶ˆæ¯å‘é€æ¨¡å—
è´Ÿè´£å¤„ç†æ‰€æœ‰ä¸æ¶ˆæ¯å‘é€ç›¸å…³çš„åŠŸèƒ½
"""

import logging
import asyncio
import re
from telegram import Bot, InputMediaPhoto
from datetime import datetime
from urllib.parse import urlparse
import requests


def extract_and_clean_media(content: str) -> list[dict]:
    """
    æå–å¹¶æ¸…ç†åª’ä½“URLï¼ˆåŒ…æ‹¬å›¾ç‰‡å’Œè§†é¢‘ï¼‰ï¼Œè¿”å›åŒ…å«ç±»å‹ä¿¡æ¯çš„åª’ä½“åˆ—è¡¨

    Args:
        content: HTMLå†…å®¹

    Returns:
        list[dict]: åª’ä½“ä¿¡æ¯åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« {'url': str, 'type': str}
                   type å¯èƒ½æ˜¯ 'image' æˆ– 'video'
    """
    media_list = []
    if not content:
        return media_list

    # æå–å›¾ç‰‡URL
    img_pattern = r'<img[^>]+src=["\']([^"\']+)["\'][^>]*>'
    raw_images = re.findall(img_pattern, content, re.IGNORECASE)
    logging.info(f"æå–åˆ° {len(raw_images)} å¼ åŸå§‹å›¾ç‰‡")

    # æå–è§†é¢‘URL
    video_pattern = r'<video[^>]+src=["\']([^"\']+)["\'][^>]*>'
    raw_videos = re.findall(video_pattern, content, re.IGNORECASE)
    logging.info(f"æå–åˆ° {len(raw_videos)} ä¸ªåŸå§‹è§†é¢‘")

    # å¤„ç†å›¾ç‰‡
    for img_url in raw_images:
        # æ¸…ç†HTMLå®ä½“ç¼–ç 
        clean_url = img_url.replace('&amp;', '&').replace('&lt;', '<').replace('&gt;', '>')
        clean_url = clean_url.replace('&quot;', '"').strip()

        # è¿‡æ»¤æ‰æ˜æ˜¾çš„å°å›¾æ ‡å’Œè£…é¥°å›¾ç‰‡
        if any(keyword in clean_url.lower() for keyword in ['icon', 'logo', 'avatar', 'emoji', 'button']):
            logging.debug(f"è¿‡æ»¤è£…é¥°å›¾ç‰‡: {clean_url}")
            continue

        # éªŒè¯URLæ ¼å¼
        if clean_url.startswith(('http://', 'https://')):
            media_list.append({'url': clean_url, 'type': 'image'})
            logging.debug(f"æ·»åŠ æœ‰æ•ˆå›¾ç‰‡: {clean_url}")
        else:
            logging.warning(f"è·³è¿‡æ— æ•ˆå›¾ç‰‡URL: {clean_url}")

    # å¤„ç†è§†é¢‘
    for video_url in raw_videos:
        # æ¸…ç†HTMLå®ä½“ç¼–ç 
        clean_url = video_url.replace('&amp;', '&').replace('&lt;', '<').replace('&gt;', '>')
        clean_url = clean_url.replace('&quot;', '"').strip()

        # éªŒè¯URLæ ¼å¼
        if clean_url.startswith(('http://', 'https://')):
            media_list.append({'url': clean_url, 'type': 'video'})
            logging.debug(f"æ·»åŠ æœ‰æ•ˆè§†é¢‘: {clean_url}")
        else:
            logging.warning(f"è·³è¿‡æ— æ•ˆè§†é¢‘URL: {clean_url}")

    logging.info(f"æ¸…ç†åæœ‰æ•ˆåª’ä½“æ•°é‡: {len(media_list)} (å›¾ç‰‡: {len(raw_images)}, è§†é¢‘: {len(raw_videos)})")

    # è®°å½•å‰å‡ ä¸ªåª’ä½“URLç”¨äºè°ƒè¯•
    for i, media_info in enumerate(media_list[:3], 1):
        media_type = "å›¾ç‰‡" if media_info['type'] == 'image' else "è§†é¢‘"
        logging.info(f"åª’ä½“{i}({media_type}): {media_info['url']}")

    return media_list


def calculate_balanced_batches(total_images: int, max_per_batch: int = 10) -> list[int]:
    """
    è®¡ç®—å‡è¡¡çš„å›¾ç‰‡åˆ†æ‰¹æ–¹æ¡ˆ

    Args:
        total_images: æ€»å›¾ç‰‡æ•°é‡
        max_per_batch: æ¯æ‰¹æœ€å¤§å›¾ç‰‡æ•°é‡

    Returns:
        list[int]: æ¯æ‰¹çš„å›¾ç‰‡æ•°é‡åˆ—è¡¨
    """
    if total_images <= max_per_batch:
        return [total_images]

    # è®¡ç®—éœ€è¦å¤šå°‘æ‰¹
    num_batches = (total_images + max_per_batch - 1) // max_per_batch

    # è®¡ç®—åŸºç¡€æ¯æ‰¹æ•°é‡
    base_size = total_images // num_batches
    remainder = total_images % num_batches

    # æ„å»ºåˆ†æ‰¹æ–¹æ¡ˆï¼šå‰remainderæ‰¹å¤š1å¼ ï¼Œåé¢çš„æ‰¹æ¬¡ä¸ºbase_size
    batch_sizes = []
    for i in range(num_batches):
        if i < remainder:
            batch_sizes.append(base_size + 1)
        else:
            batch_sizes.append(base_size)

    logging.info(f"å‡è¡¡åˆ†æ‰¹æ–¹æ¡ˆ: æ€»æ•°{total_images}, åˆ†{num_batches}æ‰¹, æ–¹æ¡ˆ{batch_sizes}")
    return batch_sizes


async def send_media_groups_with_caption(
    bot: Bot,
    chat_id: str,
    title: str,
    author: str,
    media_list: list[dict],
    full_caption: str = None
) -> None:
    """
    å‘é€åª’ä½“ç»„ï¼ˆå›¾ç‰‡å’Œè§†é¢‘ï¼‰ï¼Œæ”¯æŒä¸¤ç§captionæ ¼å¼ï¼š
    1. ç®€æ´æ ¼å¼ï¼š#ä½œè€… + title + æ‰¹æ¬¡ä¿¡æ¯ï¼ˆç”¨äºåª’ä½“ä¸ºä¸»æ¨¡å¼ï¼‰
    2. å®Œæ•´æ ¼å¼ï¼šä¼ å…¥å®Œæ•´çš„captionå†…å®¹ï¼ˆç”¨äºæ–‡å­—ä¸ºä¸»æ¨¡å¼ï¼‰

    Args:
        bot: Telegram Botå®ä¾‹
        chat_id: ç›®æ ‡èŠå¤©ID
        title: æ ‡é¢˜
        author: ä½œè€…
        media_list: åª’ä½“ä¿¡æ¯åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« {'url': str, 'type': str}
        full_caption: å®Œæ•´çš„captionå†…å®¹ï¼ˆå¯é€‰ï¼Œå¦‚æœæä¾›åˆ™ä½¿ç”¨å®Œæ•´æ ¼å¼ï¼‰

    Raises:
        MediaAccessError: å½“åª’ä½“æ— æ³•è®¿é—®æ—¶æŠ›å‡ºï¼Œè°ƒç”¨æ–¹å¯ä»¥é™çº§åˆ°æ–‡å­—æ¨¡å¼
    """
    if not media_list:
        logging.warning("send_media_groups_with_caption: æ²¡æœ‰åª’ä½“å¯å‘é€")
        return

    # ğŸ” åˆ†æåª’ä½“æ–‡ä»¶å¤§å°ä¿¡æ¯ï¼ˆä¸è¿‡æ»¤ï¼Œåªè®°å½•ï¼‰
    media_analysis = analyze_media_files_info(media_list)

    # ğŸ” è¯¦ç»†æ‰“å°æ¯ä¸ªåª’ä½“æ–‡ä»¶çš„å¤§å°ä¿¡æ¯
    logging.info(f"ğŸ“Š åª’ä½“æ–‡ä»¶è¯¦ç»†ä¿¡æ¯:")
    for detail in media_analysis['details']:
        media_type_name = detail['type_name']
        index = detail['index']
        accessible = detail['accessible']
        size_mb = detail['size_mb']
        url = detail['url']

        if accessible:
            if size_mb > 0:
                # åˆ¤æ–­æ˜¯å¦å¯èƒ½å¯¼è‡´å‘é€å¤±è´¥
                risk_level = ""
                if size_mb > 50:
                    risk_level = " ğŸš¨ é«˜é£é™©ï¼šè¶…è¿‡50MB Bot APIé™åˆ¶"
                elif size_mb > 20:
                    risk_level = " âš ï¸ ä¸­é£é™©ï¼šè¾ƒå¤§æ–‡ä»¶"
                elif size_mb > 10:
                    risk_level = " âš¡ ä½é£é™©ï¼šä¸­ç­‰å¤§å°"

                logging.info(f"   {media_type_name}{index}: {size_mb:.2f}MB{risk_level}")
            else:
                logging.info(f"   {media_type_name}{index}: å¤§å°æœªçŸ¥ â“")
        else:
            logging.info(f"   {media_type_name}{index}: æ— æ³•è®¿é—® âŒ - {detail['error_msg']}")

        logging.info(f"   URL: {url}")

    # åˆ¤æ–­ä½¿ç”¨å“ªç§captionæ ¼å¼
    use_full_caption = full_caption is not None

    if use_full_caption:
        logging.info(f"å¼€å§‹å‘é€å¸¦å®Œæ•´captionçš„åª’ä½“ç»„: åª’ä½“æ•°é‡={len(media_list)}, captioné•¿åº¦={len(full_caption)}")

        # ç¡®ä¿captionä¸è¶…è¿‡Telegramé™åˆ¶ï¼ˆ1024å­—ç¬¦ï¼‰
        max_caption_length = 1024
        if len(full_caption) > max_caption_length:
            full_caption = full_caption[:max_caption_length-3] + "..."
            logging.info(f"Captionè¿‡é•¿å·²æˆªæ–­åˆ° {len(full_caption)} å­—ç¬¦")
    else:
        logging.info(f"å¼€å§‹å‘é€åª’ä½“ç»„: æ ‡é¢˜='{title}', ä½œè€…='{author}', åª’ä½“æ•°é‡={len(media_list)}")

        # æˆªæ–­æ ‡é¢˜ï¼ˆTelegram captioné™åˆ¶1024å­—ç¬¦ï¼‰
        max_title_length = 100
        original_title = title
        if len(title) > max_title_length:
            title = title[:max_title_length] + "..."
            logging.info(f"æ ‡é¢˜è¿‡é•¿å·²æˆªæ–­: '{original_title}' -> '{title}'")

    # è®¡ç®—å‡è¡¡çš„åˆ†æ‰¹æ–¹æ¡ˆ
    batch_sizes = calculate_balanced_batches(len(media_list), max_per_batch=10)
    total_batches = len(batch_sizes)

    logging.info(f"å°†å‘é€ {total_batches} ä¸ªåª’ä½“ç»„ï¼Œåˆ†æ‰¹æ–¹æ¡ˆ: {batch_sizes}")

    # è®°å½•æ˜¯å¦æœ‰ä»»ä½•æ‰¹æ¬¡å‘é€æˆåŠŸ
    any_batch_success = False
    media_access_errors = []

    # æŒ‰ç…§åˆ†æ‰¹æ–¹æ¡ˆå‘é€åª’ä½“
    media_index = 0
    for batch_num, batch_size in enumerate(batch_sizes, 1):
        # è·å–å½“å‰æ‰¹æ¬¡çš„åª’ä½“
        batch_media = media_list[media_index:media_index + batch_size]
        media_index += batch_size

        logging.info(f"å‡†å¤‡å‘é€ç¬¬ {batch_num}/{total_batches} æ‰¹ï¼ŒåŒ…å« {batch_size} ä¸ªåª’ä½“")

        # æ„å»ºcaption
        if use_full_caption:
            # å®Œæ•´captionæ ¼å¼
            if batch_num == 1:
                # ç¬¬ä¸€æ‰¹ï¼šä½¿ç”¨å®Œæ•´caption
                if total_batches > 1:
                    # å¦‚æœæœ‰å¤šæ‰¹ï¼Œåœ¨ç¬¬ä¸€æ‰¹captionåæ·»åŠ æ‰¹æ¬¡ä¿¡æ¯ï¼ˆå‰é¢åŠ ç©ºæ ¼ï¼‰
                    caption = f"{full_caption}\n\n {batch_num}/{total_batches}"
                else:
                    # åªæœ‰ä¸€æ‰¹ï¼Œç›´æ¥ä½¿ç”¨å®Œæ•´caption
                    caption = full_caption
            else:
                # åç»­æ‰¹æ¬¡ï¼šåªæ˜¾ç¤ºæ‰¹æ¬¡ä¿¡æ¯ï¼ˆå‰é¢åŠ ç©ºæ ¼ï¼‰
                caption = f" {batch_num}/{total_batches}"
        else:
            # ç®€æ´captionæ ¼å¼ï¼š#ä½œè€… + title + æ‰¹æ¬¡ä¿¡æ¯
            caption_parts = []

            # æ·»åŠ ä½œè€…ï¼ˆå¦‚æœæœ‰ï¼‰
            if author:
                caption_parts.append(f"#{author}")
                logging.debug(f"æ·»åŠ ä½œè€…æ ‡ç­¾: #{author}")

            # æ·»åŠ æ ‡é¢˜
            caption_parts.append(title)

            # åªåœ¨å¤šæ‰¹æ¬¡æ—¶æ˜¾ç¤ºæ‰¹æ¬¡ä¿¡æ¯
            if total_batches > 1:
                batch_info = f"{batch_num}/{total_batches}"
                caption_parts.append(batch_info)
                logging.debug(f"æ·»åŠ æ‰¹æ¬¡ä¿¡æ¯: {batch_info}")

            caption = " ".join(caption_parts)

        logging.info(f"ç¬¬ {batch_num} æ‰¹captioné•¿åº¦: {len(caption)}")

        # æ„å»ºåª’ä½“ç»„
        telegram_media_list = []

        # æ¯ä¸ªæ‰¹æ¬¡çš„ç¬¬ä¸€ä¸ªåª’ä½“åŒ…å«caption
        for j, media_info in enumerate(batch_media):
            media_url = media_info['url']
            media_type = media_info['type']

            # æ ¹æ®åª’ä½“ç±»å‹æ„å»ºå¯¹åº”çš„InputMediaå¯¹è±¡
            if media_type == 'video':
                # è§†é¢‘æ–‡ä»¶
                if j == 0:  # æ¯æ‰¹çš„ç¬¬ä¸€ä¸ªåª’ä½“åŒ…å«caption
                    from telegram import InputMediaVideo
                    telegram_media_list.append(InputMediaVideo(media=media_url, caption=caption))
                    logging.debug(f"ç¬¬ {batch_num} æ‰¹ç¬¬1ä¸ªåª’ä½“(è§†é¢‘,å¸¦caption): {media_url}")
                else:
                    from telegram import InputMediaVideo
                    telegram_media_list.append(InputMediaVideo(media=media_url))
                    logging.debug(f"ç¬¬ {batch_num} æ‰¹ç¬¬{j+1}ä¸ªåª’ä½“(è§†é¢‘): {media_url}")
            else:  # media_type == 'image'
                # å›¾ç‰‡æ–‡ä»¶
                if j == 0:  # æ¯æ‰¹çš„ç¬¬ä¸€ä¸ªåª’ä½“åŒ…å«caption
                    telegram_media_list.append(InputMediaPhoto(media=media_url, caption=caption))
                    logging.debug(f"ç¬¬ {batch_num} æ‰¹ç¬¬1ä¸ªåª’ä½“(å›¾ç‰‡,å¸¦caption): {media_url}")
                else:
                    telegram_media_list.append(InputMediaPhoto(media=media_url))
                    logging.debug(f"ç¬¬ {batch_num} æ‰¹ç¬¬{j+1}ä¸ªåª’ä½“(å›¾ç‰‡): {media_url}")

        try:
            # å‘é€åª’ä½“ç»„
            await bot.send_media_group(chat_id=chat_id, media=telegram_media_list)
            logging.info(f"âœ… æˆåŠŸå‘é€ç¬¬ {batch_num}/{total_batches} æ‰¹åª’ä½“ç»„ ({batch_size}ä¸ªåª’ä½“)")
            any_batch_success = True
        except Exception as e:
            logging.error(f"âŒ å‘é€ç¬¬ {batch_num} æ‰¹åª’ä½“ç»„å¤±è´¥: {str(e)}", exc_info=True)

            # å¦‚æœæ˜¯åª’ä½“æ— æ³•è®¿é—®çš„é”™è¯¯ï¼Œè®°å½•è¯¦ç»†ä¿¡æ¯
            if "webpage_media_empty" in str(e):
                logging.error(f"åª’ä½“æ— æ³•è®¿é—®é”™è¯¯ï¼Œæ‰¹æ¬¡ {batch_num} çš„åª’ä½“URL:")
                for j, media_info in enumerate(batch_media):
                    media_type = "å›¾ç‰‡" if media_info['type'] == 'image' else "è§†é¢‘"
                    logging.error(f"  åª’ä½“{j+1}({media_type}): {media_info['url']}")
                media_access_errors.append(f"æ‰¹æ¬¡{batch_num}: {str(e)}")
                # ç»§ç»­å¤„ç†ä¸‹ä¸€æ‰¹
                continue

            # å¦‚æœå‘é€å¤±è´¥ï¼Œå°è¯•é€ä¸ªå‘é€ï¼ˆé™çº§å¤„ç†ï¼‰
            logging.info(f"å°è¯•é€ä¸ªå‘é€ç¬¬ {batch_num} æ‰¹çš„åª’ä½“...")
            batch_success = False
            for j, media_info in enumerate(batch_media):
                media_url = media_info['url']
                media_type = media_info['type']

                try:
                    if media_type == 'video':
                        # å‘é€è§†é¢‘
                        if j == 0:
                            await bot.send_video(chat_id=chat_id, video=media_url, caption=caption)
                        else:
                            await bot.send_video(chat_id=chat_id, video=media_url)
                        logging.info(f"âœ… é€ä¸ªå‘é€è§†é¢‘æˆåŠŸ: {media_url}")
                        batch_success = True
                    else:  # media_type == 'image'
                        # å‘é€å›¾ç‰‡
                        if j == 0:
                            await bot.send_photo(chat_id=chat_id, photo=media_url, caption=caption)
                        else:
                            await bot.send_photo(chat_id=chat_id, photo=media_url)
                        logging.info(f"âœ… é€ä¸ªå‘é€å›¾ç‰‡æˆåŠŸ: {media_url}")
                        batch_success = True
                except Exception as single_error:
                    media_type_name = "è§†é¢‘" if media_type == 'video' else "å›¾ç‰‡"
                    logging.error(f"âŒ é€ä¸ªå‘é€{media_type_name}å¤±è´¥: {media_url}, é”™è¯¯: {str(single_error)}", exc_info=True)

            if batch_success:
                any_batch_success = True

    # å¦‚æœæ‰€æœ‰æ‰¹æ¬¡éƒ½å› ä¸ºåª’ä½“æ— æ³•è®¿é—®è€Œå¤±è´¥ï¼ŒæŠ›å‡ºç‰¹æ®Šå¼‚å¸¸
    if not any_batch_success and media_access_errors:
        error_msg = f"æ‰€æœ‰åª’ä½“éƒ½æ— æ³•è®¿é—®: {'; '.join(media_access_errors)}"
        logging.error(f"åª’ä½“ç»„å‘é€å®Œå…¨å¤±è´¥: {error_msg}", exc_info=True)
        # å®šä¹‰ä¸€ä¸ªè‡ªå®šä¹‰å¼‚å¸¸ç±»
        class MediaAccessError(Exception):
            pass
        raise MediaAccessError(error_msg)


async def send_text_message(
    bot: Bot,
    chat_id: str,
    title: str,
    link: str,
    content: str,
    published_time: str
) -> None:
    """
    å‘é€çº¯æ–‡å­—æ¶ˆæ¯ï¼ˆæ–‡å­—ä¸ºä¸»æ¨¡å¼ï¼‰
    """
    try:
        # æ„å»ºæ¶ˆæ¯å†…å®¹
        message_parts = []

        # æ·»åŠ æ ‡é¢˜
        if title:
            message_parts.append(f"ğŸ“° {title}")

        # æ·»åŠ å†…å®¹ï¼ˆé™åˆ¶é•¿åº¦ï¼‰
        if content:
            # æ¸…ç†HTMLæ ‡ç­¾
            clean_content = re.sub(r'<[^>]+>', '', content)
            clean_content = clean_content.replace('&nbsp;', ' ').replace('&amp;', '&')
            clean_content = clean_content.replace('&lt;', '<').replace('&gt;', '>')
            clean_content = clean_content.replace('&quot;', '"').strip()

            # é™åˆ¶å†…å®¹é•¿åº¦
            max_content_length = 500
            if len(clean_content) > max_content_length:
                clean_content = clean_content[:max_content_length] + "..."

            if clean_content:
                message_parts.append(f"\n{clean_content}")

        # æ·»åŠ å‘å¸ƒæ—¶é—´
        if published_time:
            message_parts.append(f"\nâ° {published_time}")

        # æ·»åŠ é“¾æ¥
        if link:
            message_parts.append(f"\nğŸ”— {link}")

        message = "".join(message_parts)

        # å‘é€æ¶ˆæ¯
        await bot.send_message(chat_id=chat_id, text=message)
        logging.info(f"âœ… æ–‡å­—æ¶ˆæ¯å‘é€æˆåŠŸ: '{title}'")

    except Exception as e:
        logging.error(f"âŒ å‘é€æ–‡å­—æ¶ˆæ¯å¤±è´¥: '{title}', é”™è¯¯: {str(e)}", exc_info=True)
        raise


async def send_update_notification(
    bot: Bot,
    url: str,
    new_entries: list[dict],
    xml_content: str | None,
    target_chat: str = None,
) -> None:
    """
    å‘é€Feedæ›´æ–°é€šçŸ¥ï¼ŒåŒ…æ‹¬æ–°å¢æ¡ç›®åˆ—è¡¨ã€‚
    ä½¿ç”¨æ™ºèƒ½æ¶ˆæ¯å‘é€ï¼š
    - å›¾ç‰‡ä¸ºä¸»æ¨¡å¼ï¼ˆâ‰¥2å¼ å›¾ç‰‡ï¼‰ï¼šåª’ä½“ç»„ + ç®€æ´caption
    - æ–‡å­—ä¸ºä¸»æ¨¡å¼ï¼ˆ<2å¼ å›¾ç‰‡ï¼‰ï¼šå®Œæ•´æ–‡å­—å†…å®¹ + å›¾ç‰‡è¡¥å……
    - æ”¯æŒå‡è¡¡åˆ†æ‰¹ï¼Œæ¯æ‰¹æœ€å¤š10å¼ å›¾ç‰‡ï¼Œåˆ†å¸ƒæ›´å‡åŒ€
    """
    from core.config import telegram_config
    from .entry_processor import process_and_send_entry

    chat_id = target_chat or telegram_config["target_chat"]
    if not chat_id:
        logging.error("æœªé…ç½®å‘é€ç›®æ ‡ï¼Œè¯·æ£€æŸ¥TELEGRAM_TARGET_CHATç¯å¢ƒå˜é‡")
        return

    domain = urlparse(url).netloc

    try:
        # åªå‘é€æ¡ç›®å†…å®¹ï¼Œä¸å‘é€å¼€å§‹å’Œç»“æŸé€šçŸ¥
        if new_entries:
            logging.info(f"å¼€å§‹å‘é€ {len(new_entries)} ä¸ªæ¡ç›® for {domain}")

            for i, entry in enumerate(new_entries, 1):
                try:
                    # å‘é€æ¡ç›®æ¶ˆæ¯ï¼ˆåŒ…å«å›¾ç‰‡ï¼‰
                    await process_and_send_entry(bot, chat_id, entry, i, len(new_entries))
                    logging.info(f"å·²å‘é€æ¡ç›®: {entry.get('title', 'Unknown')}")

                    # æ§åˆ¶å‘é€é€Ÿåº¦ï¼Œé¿å…flood exceed
                    # Telegramé™åˆ¶ï¼šåŒä¸€èŠå¤©æ¯ç§’æœ€å¤š1æ¡æ¶ˆæ¯ï¼Œæ¯åˆ†é’Ÿæœ€å¤š20æ¡æ¶ˆæ¯
                    if i % 10 == 0:  # æ¯10æ¡æ¶ˆæ¯æš‚åœ1åˆ†é’Ÿ
                        logging.info(f"å·²å‘é€10æ¡æ¶ˆæ¯ï¼Œæš‚åœ60ç§’é¿å…flood exceed...")
                        await asyncio.sleep(60)
                    else:
                        # æ¯æ¡æ¶ˆæ¯é—´éš”8ç§’ï¼Œç¡®ä¿ä¸ä¼šè§¦å‘flood control
                        logging.debug(f"ç­‰å¾…8ç§’åå‘é€ä¸‹ä¸€æ¡ç›®...")
                        await asyncio.sleep(8)

                except Exception as e:
                    logging.error(f"å‘é€æ¡ç›®å¤±è´¥: {entry.get('title', 'Unknown')}, é”™è¯¯: {str(e)}", exc_info=True)
                    # å‡ºé”™åä¹Ÿè¦ç­‰å¾…ï¼Œé¿å…è¿ç»­é”™è¯¯
                    await asyncio.sleep(5)
                    continue

            logging.info(f"å·²å‘é€ {len(new_entries)} ä¸ªæ¡ç›® for {domain}")
        else:
            logging.info(f"{domain} æ— æ–°å¢å†…å®¹ï¼Œè·³è¿‡å‘é€")
    except Exception as e:
        logging.error(f"å‘é€Feedæ›´æ–°æ¶ˆæ¯å¤±è´¥ for {url}: {str(e)}", exc_info=True)


def check_media_accessibility(media_url: str, max_size_mb: int = 45) -> tuple[bool, str, int]:
    """
    æ£€æŸ¥åª’ä½“æ–‡ä»¶çš„å¯è®¿é—®æ€§å’Œå¤§å°

    Args:
        media_url: åª’ä½“URL
        max_size_mb: æœ€å¤§å…è®¸å¤§å°ï¼ˆMBï¼‰

    Returns:
        tuple[bool, str, int]: (æ˜¯å¦å¯è®¿é—®, é”™è¯¯ä¿¡æ¯, æ–‡ä»¶å¤§å°MB)
    """
    try:
        # å‘é€HEADè¯·æ±‚æ£€æŸ¥æ–‡ä»¶ä¿¡æ¯
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"
        }

        response = requests.head(media_url, headers=headers, timeout=10, allow_redirects=True)

        if response.status_code != 200:
            return False, f"HTTP {response.status_code}", 0

        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        content_length = response.headers.get('content-length')
        if content_length:
            size_bytes = int(content_length)
            size_mb = size_bytes / (1024 * 1024)

            if size_mb > max_size_mb:
                return False, f"æ–‡ä»¶è¿‡å¤§ ({size_mb:.1f}MB > {max_size_mb}MB)", int(size_mb)

            return True, "", int(size_mb)
        else:
            # æ— æ³•è·å–æ–‡ä»¶å¤§å°ï¼Œå‡è®¾å¯ä»¥å°è¯•
            return True, "æ— æ³•è·å–æ–‡ä»¶å¤§å°", 0

    except requests.exceptions.RequestException as e:
        return False, f"ç½‘ç»œé”™è¯¯: {str(e)}", 0
    except Exception as e:
        return False, f"æ£€æŸ¥å¤±è´¥: {str(e)}", 0


def analyze_media_files_info(media_list: list[dict]) -> dict:
    """
    åˆ†æåª’ä½“æ–‡ä»¶åˆ—è¡¨çš„å¤§å°ä¿¡æ¯ï¼Œåªæ£€æŸ¥ä¸è¿‡æ»¤

    Args:
        media_list: åª’ä½“ä¿¡æ¯åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« {'url': str, 'type': str}

    Returns:
        dict: åŒ…å«åˆ†æç»“æœçš„å­—å…¸
    """
    if not media_list:
        return {
            'total_count': 0,
            'total_size_mb': 0,
            'large_files_count': 0,
            'accessible_count': 0,
            'details': []
        }

    logging.info(f"ğŸ” å¼€å§‹åˆ†æ {len(media_list)} ä¸ªåª’ä½“æ–‡ä»¶çš„å¤§å°ä¿¡æ¯...")

    total_size_mb = 0
    large_files_count = 0
    accessible_count = 0
    details = []

    for i, media_info in enumerate(media_list, 1):
        media_url = media_info['url']
        media_type = media_info['type']
        media_type_name = "è§†é¢‘" if media_type == 'video' else "å›¾ç‰‡"

        # æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼ˆè®¾ç½®å¾ˆå¤§çš„é™åˆ¶ï¼Œä¸è¿‡æ»¤ä»»ä½•æ–‡ä»¶ï¼‰
        accessible, error_msg, size_mb = check_media_accessibility(media_url, max_size_mb=999999)

        file_info = {
            'index': i,
            'url': media_url,
            'type': media_type,
            'type_name': media_type_name,
            'accessible': accessible,
            'size_mb': size_mb,
            'error_msg': error_msg
        }

        if accessible:
            accessible_count += 1
            if size_mb > 0:
                total_size_mb += size_mb
                size_status = ""

                # æ ‡è®°å¤§æ–‡ä»¶
                if media_type == 'video' and size_mb > 50:
                    large_files_count += 1
                    size_status = " âš ï¸ è¶…è¿‡Bot API 50MBé™åˆ¶"
                elif media_type == 'image' and size_mb > 10:
                    large_files_count += 1
                    size_status = " âš ï¸ è¾ƒå¤§å›¾ç‰‡æ–‡ä»¶"

                logging.info(f"ğŸ“ {media_type_name}{i}: {size_mb:.1f}MB{size_status}")
                file_info['size_status'] = size_status
            else:
                logging.info(f"ğŸ“ {media_type_name}{i}: å¤§å°æœªçŸ¥")
                file_info['size_status'] = " â„¹ï¸ å¤§å°æœªçŸ¥"

            logging.info(f"ğŸ”— URL: {media_url}")
        else:
            logging.warning(f"âŒ {media_type_name}{i}: æ— æ³•è®¿é—® - {error_msg}")
            logging.warning(f"ğŸ”— URL: {media_url}")
            file_info['size_status'] = f" âŒ æ— æ³•è®¿é—®: {error_msg}"

        details.append(file_info)

    # æ‰“å°æ±‡æ€»ä¿¡æ¯
    analysis_result = {
        'total_count': len(media_list),
        'accessible_count': accessible_count,
        'total_size_mb': total_size_mb,
        'large_files_count': large_files_count,
        'details': details
    }

    logging.info(f"ğŸ“Š åª’ä½“æ–‡ä»¶åˆ†ææ±‡æ€»:")
    logging.info(f"   æ€»æ–‡ä»¶æ•°: {analysis_result['total_count']}")
    logging.info(f"   å¯è®¿é—®æ–‡ä»¶: {analysis_result['accessible_count']}")
    if total_size_mb > 0:
        logging.info(f"   æ€»å¤§å°: {total_size_mb:.1f}MB")
    logging.info(f"   å¤§æ–‡ä»¶æ•°é‡: {large_files_count}")

    return analysis_result