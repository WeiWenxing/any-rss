"""
å…¬å…±åª’ä½“è§£æå™¨æ¨¡å—

è¯¥æ¨¡å—æä¾›è·¨æ¨¡å—çš„ç»Ÿä¸€åª’ä½“æå–åŠŸèƒ½ï¼Œé¿å…æ¨¡å—é—´çš„ç›´æ¥ä¾èµ–ã€‚
ä»HTMLå†…å®¹ä¸­æå–å›¾ç‰‡å’Œè§†é¢‘ç­‰åª’ä½“ä¿¡æ¯ã€‚

ä¸»è¦åŠŸèƒ½ï¼š
1. HTMLå†…å®¹è§£æ
2. å›¾ç‰‡æ ‡ç­¾æå–
3. è§†é¢‘æ ‡ç­¾æå–ï¼ˆåŒ…æ‹¬å°é¢å›¾ï¼‰
4. åª’ä½“URLéªŒè¯å’Œæ¸…ç†

ä½œè€…: Assistant
åˆ›å»ºæ—¶é—´: 2024å¹´
"""

import logging
from typing import List, Dict, Optional
from bs4 import BeautifulSoup


class CommonMediaParser:
    """
    å…¬å…±åª’ä½“è§£æå™¨

    æä¾›è·¨æ¨¡å—çš„ç»Ÿä¸€åª’ä½“æå–åŠŸèƒ½ï¼Œé¿å…æ¨¡å—é—´çš„ç›´æ¥ä¾èµ–
    """

    def __init__(self):
        """åˆå§‹åŒ–åª’ä½“è§£æå™¨"""
        self.logger = logging.getLogger(__name__)

    def parse_html_content(self, html_content: str) -> Optional[BeautifulSoup]:
        """
        è§£æHTMLå†…å®¹

        Args:
            html_content: HTMLå†…å®¹å­—ç¬¦ä¸²

        Returns:
            Optional[BeautifulSoup]: è§£æåçš„soupå¯¹è±¡ï¼Œå¤±è´¥è¿”å›None
        """
        if not html_content:
            return None

        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            self.logger.debug("HTMLå†…å®¹è§£ææˆåŠŸ")
            return soup
        except Exception as e:
            self.logger.error(f"HTMLå†…å®¹è§£æå¤±è´¥: {str(e)}")
            return None

    def extract_media_from_html(self, html_content: str) -> List[Dict]:
        """
        ä»HTMLå†…å®¹ä¸­æå–åª’ä½“ä¿¡æ¯

        Args:
            html_content: HTMLå†…å®¹

        Returns:
            List[Dict]: åª’ä½“ä¿¡æ¯åˆ—è¡¨ [{'url': str, 'type': str, 'poster': str}, ...]
                       type å¯èƒ½æ˜¯ 'image' æˆ– 'video'
                       poster ä»…å¯¹è§†é¢‘æœ‰æ•ˆï¼ŒåŒ…å«å°é¢å›¾URL
        """
        media_list = []
        soup = self.parse_html_content(html_content)

        if not soup:
            self.logger.warning("HTMLè§£æå¤±è´¥ï¼Œæ— æ³•æå–åª’ä½“")
            return media_list

        # æå–å›¾ç‰‡
        img_tags = soup.find_all('img', src=True)
        self.logger.info(f"æå–åˆ° {len(img_tags)} å¼ å›¾ç‰‡")

        for img_tag in img_tags:
            img_url = img_tag.get('src', '').strip()
            if not img_url or not img_url.startswith(('http://', 'https://')):
                continue

            # è¿‡æ»¤è£…é¥°å›¾ç‰‡
            if any(keyword in img_url.lower() for keyword in ['icon', 'logo', 'avatar', 'emoji', 'button']):
                self.logger.debug(f"è¿‡æ»¤è£…é¥°å›¾ç‰‡: {img_url}")
                continue

            media_list.append({'url': img_url, 'type': 'image'})
            self.logger.debug(f"æ·»åŠ å›¾ç‰‡: {img_url}")

        # æå–è§†é¢‘
        video_tags = soup.find_all('video', src=True)
        self.logger.info(f"æå–åˆ° {len(video_tags)} ä¸ªè§†é¢‘")

        for video_tag in video_tags:
            video_url = video_tag.get('src', '').strip()
            poster_url = video_tag.get('poster', '').strip()

            if not video_url or not video_url.startswith(('http://', 'https://')):
                continue

            media_info = {'url': video_url, 'type': 'video'}

            # æ·»åŠ å°é¢å›¾ï¼ˆå¦‚æœæœ‰æ•ˆï¼‰
            if poster_url and poster_url.startswith(('http://', 'https://')):
                media_info['poster'] = poster_url
                self.logger.debug(f"æ·»åŠ è§†é¢‘(å«å°é¢): {video_url} -> {poster_url}")
            else:
                self.logger.debug(f"æ·»åŠ è§†é¢‘(æ— å°é¢): {video_url}")

            media_list.append(media_info)

        self.logger.info(f"åª’ä½“æå–å®Œæˆ: {len(media_list)} ä¸ªåª’ä½“æ–‡ä»¶")
        return media_list


# å…¨å±€è§£æå™¨å®ä¾‹
_media_parser_instance = None


def get_common_media_parser() -> CommonMediaParser:
    """
    è·å–å…¬å…±åª’ä½“è§£æå™¨å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰

    Returns:
        CommonMediaParser: åª’ä½“è§£æå™¨å®ä¾‹
    """
    global _media_parser_instance
    if _media_parser_instance is None:
        _media_parser_instance = CommonMediaParser()
        logging.info("åˆ›å»ºå…¬å…±åª’ä½“è§£æå™¨å®ä¾‹")
    return _media_parser_instance


def extract_media_from_html(html_content: str) -> List[Dict]:
    """
    ä»HTMLå†…å®¹ä¸­æå–åª’ä½“ä¿¡æ¯çš„ä¾¿æ·å‡½æ•°

    Args:
        html_content: HTMLå†…å®¹

    Returns:
        List[Dict]: åª’ä½“ä¿¡æ¯åˆ—è¡¨
    """
    parser = get_common_media_parser()
    return parser.extract_media_from_html(html_content)


if __name__ == "__main__":
    # æ¨¡å—æµ‹è¯•ä»£ç 
    def test_media_parser():
        """æµ‹è¯•åª’ä½“è§£æå™¨åŠŸèƒ½"""
        print("ğŸ§ª å…¬å…±åª’ä½“è§£æå™¨æ¨¡å—æµ‹è¯•")

        # åˆ›å»ºè§£æå™¨
        parser = get_common_media_parser()
        print(f"âœ… åˆ›å»ºåª’ä½“è§£æå™¨: {type(parser).__name__}")

        # æµ‹è¯•HTMLå†…å®¹
        test_html = '''
        <div>
            <img src="https://example.com/image1.jpg" alt="æµ‹è¯•å›¾ç‰‡1">
            <img src="https://example.com/image2.png" alt="æµ‹è¯•å›¾ç‰‡2">
            <video src="https://example.com/video1.mp4" poster="https://example.com/poster1.jpg" controls>
                Your browser does not support the video tag.
            </video>
            <video src="https://example.com/video2.mp4" controls>
                Your browser does not support the video tag.
            </video>
        </div>
        '''

        # æå–åª’ä½“
        media_list = parser.extract_media_from_html(test_html)
        print(f"âœ… æå–åˆ° {len(media_list)} ä¸ªåª’ä½“é¡¹")

        for i, media in enumerate(media_list, 1):
            media_type = "å›¾ç‰‡" if media['type'] == 'image' else "è§†é¢‘"
            poster_info = f" (å°é¢: {media.get('poster', 'æ— ')})" if media['type'] == 'video' else ""
            print(f"  {i}. {media_type}: {media['url']}{poster_info}")

        # æµ‹è¯•ä¾¿æ·å‡½æ•°
        media_list2 = extract_media_from_html(test_html)
        print(f"âœ… ä¾¿æ·å‡½æ•°æå–åˆ° {len(media_list2)} ä¸ªåª’ä½“é¡¹")

        print("ğŸ‰ å…¬å…±åª’ä½“è§£æå™¨æ¨¡å—æµ‹è¯•å®Œæˆ")

    # è¿è¡Œæµ‹è¯•
    test_media_parser()