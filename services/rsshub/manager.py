"""
RSSHubç®¡ç†å™¨æ¨¡å—

è¯¥æ¨¡å—è´Ÿè´£å¤„ç†RSSç‰¹å®šçš„ä¸šåŠ¡é€»è¾‘ï¼Œç»§æ‰¿ç»Ÿä¸€ç®¡ç†å™¨åŸºç±»çš„é€šç”¨æ•°æ®ç®¡ç†åŠŸèƒ½ã€‚
ä¸“æ³¨äºRSSè§£æã€å†…å®¹è½¬æ¢ç­‰RSSç‰¹æœ‰çš„åŠŸèƒ½ã€‚

ä¸»è¦åŠŸèƒ½ï¼š
1. RSSå†…å®¹è·å–å’Œè§£æ
2. RSSæ¡ç›®IDç”Ÿæˆ
3. RSSç‰¹å®šçš„å†…å®¹è½¬æ¢

ä½œè€…: Assistant
åˆ›å»ºæ—¶é—´: 2024å¹´
"""

import logging
from typing import List, Dict, Optional, Any, Tuple

from .rss_entry import RSSEntry
from .rss_parser import RSSParser, create_rss_parser
from services.common.unified_manager import UnifiedContentManager


class RSSHubManager(UnifiedContentManager):
    """
    RSSHubç®¡ç†å™¨

    ç»§æ‰¿ç»Ÿä¸€ç®¡ç†å™¨åŸºç±»ï¼Œä¸“æ³¨äºRSSç‰¹å®šçš„ä¸šåŠ¡é€»è¾‘
    """

    def __init__(self, data_dir: str = "storage/rsshub"):
        """
        åˆå§‹åŒ–RSSHubç®¡ç†å™¨

        Args:
            data_dir: æ•°æ®å­˜å‚¨ç›®å½•
        """
        # è°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°ï¼Œä¼ å…¥data_dirå¯ç”¨é€šç”¨æ•°æ®ç®¡ç†
        super().__init__(module_name="rsshub", data_dir=data_dir)

        # åˆå§‹åŒ–RSSç‰¹å®šç»„ä»¶
        self.rss_parser = create_rss_parser()

        # åˆå§‹åŒ–å¹¶æ³¨å†ŒRSSè½¬æ¢å™¨ï¼ˆç¡®ä¿è½¬æ¢å™¨å¯ç”¨ï¼‰
        from .rss_converter import create_rss_converter
        self.rss_converter = create_rss_converter()

        self.logger.info(f"RSSHubç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆï¼Œæ•°æ®ç›®å½•: {data_dir}")

    # ==================== å®ç°UnifiedContentManageræŠ½è±¡æ¥å£ ====================

    def fetch_latest_content(self, source_url: str) -> Tuple[bool, str, Optional[List[Dict]]]:
        """
        è·å–æŒ‡å®šæºçš„æœ€æ–°å†…å®¹ï¼ˆRSSç‰¹å®šå®ç°ï¼‰

        Args:
            source_url: æ•°æ®æºURL

        Returns:
            Tuple[bool, str, Optional[List[Dict]]]: (æ˜¯å¦æˆåŠŸ, é”™è¯¯ä¿¡æ¯, å†…å®¹æ•°æ®åˆ—è¡¨)
        """
        try:
            self.logger.info(f"ğŸ“¥ å¼€å§‹è·å–RSSå†…å®¹: {source_url}")

            # ä½¿ç”¨RSSè§£æå™¨è·å–æœ€æ–°å†…å®¹
            entries = self.rss_parser.parse_feed(source_url)

            if not entries:
                self.logger.warning(f"ğŸ“­ RSSæºæ— å†…å®¹æˆ–è§£æå¤±è´¥: {source_url}")
                return False, "RSSæºæ— å†…å®¹æˆ–è§£æå¤±è´¥", None

            self.logger.info(f"ğŸ“Š RSSè§£ææˆåŠŸ: è·å–åˆ° {len(entries)} ä¸ªæ¡ç›®")

            # è½¬æ¢ä¸ºç»Ÿä¸€çš„å†…å®¹æ•°æ®æ ¼å¼
            content_data_list = []
            for i, entry in enumerate(entries):
                try:
                    content_data = {
                        "title": entry.title,
                        "description": entry.description,
                        "link": entry.link,
                        "published": entry.published,
                        "updated": entry.updated,
                        "author": entry.author,
                        "item_id": entry.item_id,
                        "time": entry.effective_published_time.isoformat() if entry.effective_published_time else "",
                        "enclosures": [
                            {
                                "url": enc.url,
                                "type": enc.type,
                                "length": enc.length
                            } for enc in entry.enclosures
                        ] if entry.enclosures else []
                    }
                    content_data_list.append(content_data)

                    if i < 3:  # åªè®°å½•å‰3ä¸ªæ¡ç›®çš„è¯¦ç»†ä¿¡æ¯
                        self.logger.debug(f"ğŸ“„ æ¡ç›®{i+1}: {entry.title[:50]}{'...' if len(entry.title) > 50 else ''} (ID: {entry.item_id})")

                except Exception as e:
                    self.logger.warning(f"âš ï¸ è½¬æ¢æ¡ç›®{i+1}å¤±è´¥: {str(e)}")
                    continue

            self.logger.info(f"âœ… å†…å®¹è½¬æ¢å®Œæˆ: æˆåŠŸè½¬æ¢ {len(content_data_list)}/{len(entries)} ä¸ªæ¡ç›®")
            return True, "", content_data_list

        except Exception as e:
            self.logger.error(f"ğŸ’¥ è·å–RSSå†…å®¹å¤±è´¥: {source_url}, é”™è¯¯: {str(e)}", exc_info=True)
            return False, f"è·å–RSSå†…å®¹å¤±è´¥: {str(e)}", None

    def generate_content_id(self, content_data: Dict) -> str:
        """
        ç”Ÿæˆå†…å®¹çš„å”¯ä¸€æ ‡è¯†ï¼ˆRSSç‰¹å®šå®ç°ï¼‰

        Args:
            content_data: å†…å®¹æ•°æ®

        Returns:
            str: å”¯ä¸€æ ‡è¯†
        """
        # å¦‚æœå†…å®¹æ•°æ®ä¸­å·²æœ‰item_idï¼Œç›´æ¥ä½¿ç”¨
        if "item_id" in content_data and content_data["item_id"]:
            return content_data["item_id"]

        # å¦åˆ™æ ¹æ®å†…å®¹ç”ŸæˆIDï¼ˆä¸RSSè§£æå™¨çš„é€»è¾‘ä¿æŒä¸€è‡´ï¼‰
        if content_data.get("link"):
            return content_data["link"]
        elif content_data.get("title") and content_data.get("published"):
            return f"{content_data['title']}_{content_data['published']}"
        else:
            return f"rss_item_{hash(str(content_data))}"

    # ==================== RSSç‰¹å®šçš„ä¾¿åˆ©æ–¹æ³• ====================

    def get_all_rss_urls(self) -> List[str]:
        """
        è·å–æ‰€æœ‰RSSæºURLåˆ—è¡¨ï¼ˆå…¼å®¹æ€§æ–¹æ³•ï¼Œè°ƒç”¨é€šç”¨å®ç°ï¼‰

        Returns:
            List[str]: RSSæºURLåˆ—è¡¨
        """
        return self.get_all_source_urls()


def create_rsshub_manager(data_dir: str = "storage/rsshub") -> RSSHubManager:
    """
    åˆ›å»ºRSSHubç®¡ç†å™¨å®ä¾‹

    Args:
        data_dir: æ•°æ®å­˜å‚¨ç›®å½•

    Returns:
        RSSHubManager: ç®¡ç†å™¨å®ä¾‹
    """
    return RSSHubManager(data_dir)


if __name__ == "__main__":
    # æ¨¡å—æµ‹è¯•ä»£ç 
    def test_rsshub_manager():
        """æµ‹è¯•RSSHubç®¡ç†å™¨åŠŸèƒ½"""
        print("ğŸ§ª RSSHubç®¡ç†å™¨æ¨¡å—æµ‹è¯•")

        # åˆ›å»ºç®¡ç†å™¨å®ä¾‹
        manager = create_rsshub_manager("test_storage/rsshub")

        # æµ‹è¯•åŸºæœ¬åŠŸèƒ½
        print("âœ… RSSHubç®¡ç†å™¨åˆ›å»ºæˆåŠŸ")
        print(f"ğŸ“Š å½“å‰è®¢é˜…æ•°é‡: {len(manager.get_subscriptions())}")

        print("ğŸ‰ RSSHubç®¡ç†å™¨æ¨¡å—æµ‹è¯•å®Œæˆ")

    # è¿è¡Œæµ‹è¯•
    test_rsshub_manager()