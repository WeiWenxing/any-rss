"""
RSSHubè°ƒåº¦å™¨æ¨¡å—

è¯¥æ¨¡å—è´Ÿè´£RSSHubçš„å®šæ—¶ä»»åŠ¡è°ƒåº¦ï¼Œå®Œå…¨å¤ç”¨douyinæ¨¡å—çš„è°ƒåº¦é€»è¾‘ã€‚
æ”¯æŒå®šæ—¶æ£€æŸ¥RSSæ›´æ–°ã€æ‰¹é‡å‘é€æ–°å†…å®¹ã€æ¸…ç†è¿‡æœŸæ•°æ®ç­‰åŠŸèƒ½ã€‚

ä¸»è¦åŠŸèƒ½ï¼š
1. å®šæ—¶æ£€æŸ¥æ‰€æœ‰RSSæºçš„æ›´æ–°
2. æ‰¹é‡å‘é€æ–°RSSå†…å®¹åˆ°è®¢é˜…é¢‘é“
3. æ™ºèƒ½å»é‡å’Œå†…å®¹è¿‡æ»¤
4. å‘é€é—´éš”ç®¡ç†å’Œé”™è¯¯å¤„ç†
5. æ•°æ®æ¸…ç†å’Œç»´æŠ¤ä»»åŠ¡

ä½œè€…: Assistant
åˆ›å»ºæ—¶é—´: 2024å¹´
"""

import asyncio
import logging
from datetime import datetime, timedelta
from typing import List, Dict, Any
from telegram import Bot

from .manager import RSSHubManager, create_rsshub_manager
from .rss_parser import RSSParser, create_rss_parser
from .rss_converter import create_rss_converter
from .rss_entry import RSSEntry
from services.common.unified_scheduler import UnifiedScheduler


class RSSHubScheduler(UnifiedScheduler):
    """
    RSSHubå®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨

    ç»§æ‰¿ç»Ÿä¸€è°ƒåº¦å™¨åŸºç±»ï¼Œå®Œå…¨å¤ç”¨douyinæ¨¡å—çš„è°ƒåº¦é€»è¾‘ï¼Œä¸ºRSSè®¢é˜…æä¾›å®šæ—¶æ›´æ–°å’Œå‘é€åŠŸèƒ½
    """

    def __init__(self, data_dir: str = "storage/rsshub"):
        """
        åˆå§‹åŒ–RSSHubè°ƒåº¦å™¨

        Args:
            data_dir: æ•°æ®å­˜å‚¨ç›®å½•
        """
        # åˆ›å»ºRSSHubç®¡ç†å™¨
        rsshub_manager = create_rsshub_manager(data_dir)

        # è°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°
        super().__init__(module_name="rsshub", manager=rsshub_manager)

        # åˆå§‹åŒ–RSSç‰¹å®šç»„ä»¶
        self.rss_parser = create_rss_parser()
        self.rss_converter = create_rss_converter()

        # è°ƒåº¦é…ç½®ï¼ˆå¤ç”¨douyinçš„é…ç½®é€»è¾‘ï¼‰
        self.check_interval = 300  # 5åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡ï¼ˆä¸douyinä¿æŒä¸€è‡´ï¼‰
        self.max_concurrent_feeds = 5  # æœ€å¤§å¹¶å‘RSSæºæ•°é‡
        self.max_items_per_batch = 20  # æ¯æ‰¹æœ€å¤§æ¡ç›®æ•°é‡

        self.logger.info(f"RSSHubè°ƒåº¦å™¨åˆå§‹åŒ–å®Œæˆï¼Œæ£€æŸ¥é—´éš”: {self.check_interval}ç§’")

    # ==================== é‡å†™UnifiedSchedulerçš„å¯é€‰æ–¹æ³• ====================

    def get_module_display_name(self) -> str:
        """
        è·å–æ¨¡å—æ˜¾ç¤ºåç§°ï¼ˆç”¨äºæ—¥å¿—ï¼‰

        Returns:
            str: æ¨¡å—æ˜¾ç¤ºåç§°
        """
        return "RSSHUB"

    def should_skip_source(self, source_url: str) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥è·³è¿‡æŸä¸ªRSSæºï¼ˆå­ç±»å¯é‡å†™ï¼‰

        Args:
            source_url: RSSæºURL

        Returns:
            bool: æ˜¯å¦è·³è¿‡
        """
        # RSSæºä¸€èˆ¬ä¸éœ€è¦è·³è¿‡ï¼Œé™¤éæœ‰ç‰¹æ®Šéœ€æ±‚
        return False

    async def cleanup_old_files(self) -> None:
        """
        æ¸…ç†è¿‡æœŸæ–‡ä»¶ï¼ˆRSSç‰¹å®šçš„æ¸…ç†é€»è¾‘ï¼‰
        """
        try:
            self.logger.info("å¼€å§‹RSSHubæ•°æ®æ¸…ç†ä»»åŠ¡")

            # æ¸…ç†å­¤ç«‹çš„æ•°æ®
            cleaned_count = self.manager.cleanup_orphaned_data()

            # æ¸…ç†è¿‡æœŸçš„å·²çŸ¥æ¡ç›®ï¼ˆä¿ç•™æœ€è¿‘1000ä¸ªï¼‰
            await self._cleanup_old_known_items()

            self.logger.info(f"RSSHubæ•°æ®æ¸…ç†å®Œæˆï¼Œæ¸…ç†äº† {cleaned_count} ä¸ªå­¤ç«‹æ•°æ®é¡¹")

        except Exception as e:
            self.logger.error(f"RSSHubæ•°æ®æ¸…ç†å¤±è´¥: {str(e)}", exc_info=True)

    # ==================== RSSç‰¹å®šçš„è¾…åŠ©æ–¹æ³• ====================

    async def _cleanup_old_known_items(self) -> None:
        """
        æ¸…ç†è¿‡æœŸçš„å·²çŸ¥æ¡ç›®IDï¼ˆä¿ç•™æœ€è¿‘çš„æ¡ç›®ï¼‰
        """
        try:
            all_rss_urls = self.manager.get_all_rss_urls()
            max_known_items = 1000  # æ¯ä¸ªRSSæºæœ€å¤šä¿ç•™1000ä¸ªå·²çŸ¥æ¡ç›®

            for rss_url in all_rss_urls:
                try:
                    known_item_ids = self.manager.get_known_item_ids(rss_url)

                    if len(known_item_ids) > max_known_items:
                        # ä¿ç•™æœ€æ–°çš„æ¡ç›®ï¼ˆç®€å•çš„FIFOç­–ç•¥ï¼‰
                        trimmed_ids = known_item_ids[-max_known_items:]
                        self.manager.save_known_item_ids(rss_url, trimmed_ids)

                        removed_count = len(known_item_ids) - len(trimmed_ids)
                        self.logger.info(f"æ¸…ç†RSSæºè¿‡æœŸæ¡ç›®: {rss_url}, ç§»é™¤ {removed_count} ä¸ªæ—§æ¡ç›®")

                except Exception as e:
                    self.logger.warning(f"æ¸…ç†RSSæºå·²çŸ¥æ¡ç›®å¤±è´¥: {rss_url}, é”™è¯¯: {str(e)}")
                    continue

        except Exception as e:
            self.logger.error(f"æ¸…ç†å·²çŸ¥æ¡ç›®å¤±è´¥: {str(e)}", exc_info=True)

    # ==================== å…¼å®¹æ€§æ¥å£ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰====================

    async def check_all_rss_updates(self, bot: Bot) -> Dict[str, Any]:
        """
        æ£€æŸ¥æ‰€æœ‰RSSæºçš„æ›´æ–°ï¼ˆå…¼å®¹æ€§æ¥å£ï¼Œå†…éƒ¨è°ƒç”¨ç»Ÿä¸€è°ƒåº¦å™¨ï¼‰

        Args:
            bot: Telegram Botå®ä¾‹

        Returns:
            Dict[str, Any]: æ£€æŸ¥ç»“æœç»Ÿè®¡
        """
        try:
            self.logger.info("å¼€å§‹æ£€æŸ¥æ‰€æœ‰RSSæºæ›´æ–°")
            start_time = datetime.now()

            # è°ƒç”¨çˆ¶ç±»çš„ç»Ÿä¸€è°ƒåº¦é€»è¾‘
            await self.run_scheduled_check(bot)

            # è·å–ç»Ÿè®¡ä¿¡æ¯
            stats = self.get_scheduler_statistics()

            # è®°å½•æ£€æŸ¥å®Œæˆ
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()

            self.logger.info(
                f"RSSæ›´æ–°æ£€æŸ¥å®Œæˆ: "
                f"æ€»æºæ•°={stats.get('total_sources', 0)}, "
                f"æ€»è®¢é˜…={stats.get('total_subscriptions', 0)}, "
                f"è€—æ—¶={duration:.2f}ç§’"
            )

            return {
                "total_feeds": stats.get('total_sources', 0),
                "total_subscriptions": stats.get('total_subscriptions', 0),
                "duration": duration
            }

        except Exception as e:
            self.logger.error(f"æ£€æŸ¥RSSæ›´æ–°å¤±è´¥: {str(e)}", exc_info=True)
            return {"total_feeds": 0, "total_subscriptions": 0, "errors": 1}

    def get_scheduler_stats(self) -> Dict[str, Any]:
        """
        è·å–è°ƒåº¦å™¨ç»Ÿè®¡ä¿¡æ¯ï¼ˆå…¼å®¹æ€§æ¥å£ï¼‰

        Returns:
            Dict[str, Any]: ç»Ÿè®¡ä¿¡æ¯
        """
        try:
            # è·å–çˆ¶ç±»çš„ç»Ÿè®¡ä¿¡æ¯
            base_stats = self.get_scheduler_statistics()

            # æ·»åŠ RSSç‰¹å®šä¿¡æ¯
            rss_specific_stats = {
                "check_interval": self.check_interval,
                "max_concurrent_feeds": self.max_concurrent_feeds,
                "max_items_per_batch": self.max_items_per_batch,
                "last_check_time": datetime.now().isoformat()
            }

            # åˆå¹¶ç»Ÿè®¡ä¿¡æ¯
            return {**base_stats, **rss_specific_stats}

        except Exception as e:
            self.logger.error(f"è·å–è°ƒåº¦å™¨ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}", exc_info=True)
            return {}


# ä¾¿æ·å‡½æ•°ï¼šåˆ›å»ºRSSHubè°ƒåº¦å™¨å®ä¾‹
def create_rsshub_scheduler(data_dir: str = "storage/rsshub") -> RSSHubScheduler:
    """
    åˆ›å»ºRSSHubè°ƒåº¦å™¨å®ä¾‹

    Args:
        data_dir: æ•°æ®å­˜å‚¨ç›®å½•

    Returns:
        RSSHubScheduler: RSSHubè°ƒåº¦å™¨å®ä¾‹
    """
    return RSSHubScheduler(data_dir)


if __name__ == "__main__":
    # æ¨¡å—æµ‹è¯•ä»£ç 
    import asyncio

    async def test_rsshub_scheduler():
        """æµ‹è¯•RSSHubè°ƒåº¦å™¨åŠŸèƒ½"""
        print("ğŸ§ª RSSHubè°ƒåº¦å™¨æ¨¡å—æµ‹è¯•")

        # åˆ›å»ºè°ƒåº¦å™¨
        scheduler = create_rsshub_scheduler("test_data/rsshub")
        print(f"âœ… åˆ›å»ºRSSHubè°ƒåº¦å™¨: {type(scheduler).__name__}")

        # æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯
        stats = scheduler.get_scheduler_stats()
        print(f"âœ… è·å–ç»Ÿè®¡ä¿¡æ¯: {stats.get('total_sources', 0)} ä¸ªRSSæº")

        # æµ‹è¯•æ•°æ®æ¸…ç†
        await scheduler.cleanup_old_files()
        print("âœ… æ•°æ®æ¸…ç†ä»»åŠ¡å®Œæˆ")

        print("ğŸ‰ RSSHubè°ƒåº¦å™¨æ¨¡å—æµ‹è¯•å®Œæˆ")

    # è¿è¡Œæµ‹è¯•
    asyncio.run(test_rsshub_scheduler())